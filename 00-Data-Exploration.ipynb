{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMP_ID</th>\n",
       "      <th>GJ</th>\n",
       "      <th>IMPORT</th>\n",
       "      <th>MUFO_REFERENZ_N</th>\n",
       "      <th>BARCODE_NR</th>\n",
       "      <th>VERANST_SEGMENT</th>\n",
       "      <th>REKLA_JN</th>\n",
       "      <th>VG_DATUM_VON</th>\n",
       "      <th>VG_ORT</th>\n",
       "      <th>VG_RAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VERANST_ORT</th>\n",
       "      <th>NUTZLIZNEHM_GESCHAEFTSZEICHEN</th>\n",
       "      <th>NUTZLIZNEHM_NAME</th>\n",
       "      <th>NUTZLIZNEHM_VORNAME</th>\n",
       "      <th>NUTZLIZNEHM_STRASSE</th>\n",
       "      <th>NUTZLIZNEHM_PLZ</th>\n",
       "      <th>NUTZLIZNEHM_ORT</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>BAND</th>\n",
       "      <th>PROMOTER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9938765</th>\n",
       "      <td>24643</td>\n",
       "      <td>2016</td>\n",
       "      <td>ABRE U INKA 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5027961220</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NONRekla</td>\n",
       "      <td>2014-02-09</td>\n",
       "      <td>LISBERG</td>\n",
       "      <td>TURNHALLE SV RW LISBERG</td>\n",
       "      <td>...</td>\n",
       "      <td>WALSDORF</td>\n",
       "      <td>1510423300</td>\n",
       "      <td>BAYERISCHER BLASMUSIKVERBAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80084</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>LISBERG TURNHALLE SV RW LISBERG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AURACHTALER BLASMUSIKVEREIN WALSDORF E.V 96194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938766</th>\n",
       "      <td>24643</td>\n",
       "      <td>2016</td>\n",
       "      <td>ABRE U INKA 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5027961235</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NONRekla</td>\n",
       "      <td>2014-02-08</td>\n",
       "      <td>LISBERG</td>\n",
       "      <td>TURNHALLE SV RW LISBERG</td>\n",
       "      <td>...</td>\n",
       "      <td>WALSDORF</td>\n",
       "      <td>1510423300</td>\n",
       "      <td>BAYERISCHER BLASMUSIKVERBAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80084</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>LISBERG TURNHALLE SV RW LISBERG</td>\n",
       "      <td>DAS BOEHMISCHE FEUER</td>\n",
       "      <td>AURACHTALER BLASMUSIKVEREIN WALSDORF E.V 96194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938851</th>\n",
       "      <td>24643</td>\n",
       "      <td>2016</td>\n",
       "      <td>ABRE U INKA 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044481411</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NONRekla</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>WERNER-VON-SIEMENS-SCHULZENTRUM</td>\n",
       "      <td>...</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>1510423300</td>\n",
       "      <td>BAYERISCHER BLASMUSIKVERBAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80084</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>MUENCHEN WERNER-VON-SIEMENS-SCHULZENTRUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLASORCHESTER ST. MICHAEL MUENCHEN-PERLACH E.V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938852</th>\n",
       "      <td>24643</td>\n",
       "      <td>2016</td>\n",
       "      <td>ABRE U INKA 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044481427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NONRekla</td>\n",
       "      <td>2014-03-14</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>PFARRHEIM UND KIRCHE</td>\n",
       "      <td>...</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>1510423300</td>\n",
       "      <td>BAYERISCHER BLASMUSIKVERBAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80084</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>MUENCHEN PFARRHEIM UND KIRCHE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLASORCHESTER ST. MICHAEL MUENCHEN-PERLACH E.V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938853</th>\n",
       "      <td>24643</td>\n",
       "      <td>2016</td>\n",
       "      <td>ABRE U INKA 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5044481469</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NONRekla</td>\n",
       "      <td>2014-02-09</td>\n",
       "      <td>GRAFENRHEINFELD</td>\n",
       "      <td>KULTURHALLE GRAFENRHEINFELD</td>\n",
       "      <td>...</td>\n",
       "      <td>WERNECK</td>\n",
       "      <td>1510423300</td>\n",
       "      <td>BAYERISCHER BLASMUSIKVERBAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80084</td>\n",
       "      <td>MUENCHEN</td>\n",
       "      <td>GRAFENRHEINFELD KULTURHALLE GRAFENRHEINFELD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MUSIKVEREIN WERNECK E.V 97440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IMP_ID    GJ            IMPORT MUFO_REFERENZ_N  BARCODE_NR  \\\n",
       "ID                                                                    \n",
       "9938765   24643  2016  ABRE U INKA 2016             NaN  5027961220   \n",
       "9938766   24643  2016  ABRE U INKA 2016             NaN  5027961235   \n",
       "9938851   24643  2016  ABRE U INKA 2016             NaN  5044481411   \n",
       "9938852   24643  2016  ABRE U INKA 2016             NaN  5044481427   \n",
       "9938853   24643  2016  ABRE U INKA 2016             NaN  5044481469   \n",
       "\n",
       "         VERANST_SEGMENT  REKLA_JN VG_DATUM_VON           VG_ORT  \\\n",
       "ID                                                                 \n",
       "9938765              4.0  NONRekla   2014-02-09          LISBERG   \n",
       "9938766              6.0  NONRekla   2014-02-08          LISBERG   \n",
       "9938851              3.0  NONRekla   2014-03-15         MUENCHEN   \n",
       "9938852              2.0  NONRekla   2014-03-14         MUENCHEN   \n",
       "9938853              2.0  NONRekla   2014-02-09  GRAFENRHEINFELD   \n",
       "\n",
       "                                 VG_RAUM  ...  VERANST_ORT  \\\n",
       "ID                                        ...                \n",
       "9938765          TURNHALLE SV RW LISBERG  ...     WALSDORF   \n",
       "9938766          TURNHALLE SV RW LISBERG  ...     WALSDORF   \n",
       "9938851  WERNER-VON-SIEMENS-SCHULZENTRUM  ...     MUENCHEN   \n",
       "9938852             PFARRHEIM UND KIRCHE  ...     MUENCHEN   \n",
       "9938853      KULTURHALLE GRAFENRHEINFELD  ...      WERNECK   \n",
       "\n",
       "        NUTZLIZNEHM_GESCHAEFTSZEICHEN              NUTZLIZNEHM_NAME  \\\n",
       "ID                                                                    \n",
       "9938765                    1510423300  BAYERISCHER BLASMUSIKVERBAND   \n",
       "9938766                    1510423300  BAYERISCHER BLASMUSIKVERBAND   \n",
       "9938851                    1510423300  BAYERISCHER BLASMUSIKVERBAND   \n",
       "9938852                    1510423300  BAYERISCHER BLASMUSIKVERBAND   \n",
       "9938853                    1510423300  BAYERISCHER BLASMUSIKVERBAND   \n",
       "\n",
       "        NUTZLIZNEHM_VORNAME  NUTZLIZNEHM_STRASSE NUTZLIZNEHM_PLZ  \\\n",
       "ID                                                                 \n",
       "9938765                 NaN                  NaN           80084   \n",
       "9938766                 NaN                  NaN           80084   \n",
       "9938851                 NaN                  NaN           80084   \n",
       "9938852                 NaN                  NaN           80084   \n",
       "9938853                 NaN                  NaN           80084   \n",
       "\n",
       "         NUTZLIZNEHM_ORT                                     LOCATION  \\\n",
       "ID                                                                      \n",
       "9938765         MUENCHEN              LISBERG TURNHALLE SV RW LISBERG   \n",
       "9938766         MUENCHEN              LISBERG TURNHALLE SV RW LISBERG   \n",
       "9938851         MUENCHEN     MUENCHEN WERNER-VON-SIEMENS-SCHULZENTRUM   \n",
       "9938852         MUENCHEN                MUENCHEN PFARRHEIM UND KIRCHE   \n",
       "9938853         MUENCHEN  GRAFENRHEINFELD KULTURHALLE GRAFENRHEINFELD   \n",
       "\n",
       "                         BAND  \\\n",
       "ID                              \n",
       "9938765                   NaN   \n",
       "9938766  DAS BOEHMISCHE FEUER   \n",
       "9938851                   NaN   \n",
       "9938852                   NaN   \n",
       "9938853                   NaN   \n",
       "\n",
       "                                                  PROMOTER  \n",
       "ID                                                          \n",
       "9938765     AURACHTALER BLASMUSIKVEREIN WALSDORF E.V 96194  \n",
       "9938766     AURACHTALER BLASMUSIKVEREIN WALSDORF E.V 96194  \n",
       "9938851  BLASORCHESTER ST. MICHAEL MUENCHEN-PERLACH E.V...  \n",
       "9938852  BLASORCHESTER ST. MICHAEL MUENCHEN-PERLACH E.V...  \n",
       "9938853                      MUSIKVEREIN WERNECK E.V 97440  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv('C:/Saravana/Data/Raw/2016.log')\n",
    "df = pd.read_pickle('C:/Saravana/Data/Raw/export-cleansed-4851f054c66579780503d70880731802.pkl.bz2')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.VERANST_SEGMENT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.VG_RAUM.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296137"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the event segments > 3 to a event segment - 4\n",
    "df.loc[df['VERANST_SEGMENT'] > 3, 'VERANST_SEGMENT'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296137"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter segment 2(0-50 euros) & segment 3(50-100 euros) & segment 4(>100 euros)\n",
    "allclaims_df = df.query('VERANST_SEGMENT <= 4')\n",
    "len(allclaims_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2029523"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter segment 2(0-50 euros) & segment 3(50-100 euros) \n",
    "# lowerclaim_df = df.query('VERANST_SEGMENT <= 3')\n",
    "# len(lowerclaim_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2029377"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values from VG_ORT\n",
    "allclaims_df = allclaims_df[allclaims_df['VG_ORT'].isnull()==False]\n",
    "len(allclaims_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IMP_ID', 'GJ', 'IMPORT', 'MUFO_REFERENZ_N', 'BARCODE_NR',\n",
       "       'VERANST_SEGMENT', 'REKLA_JN', 'VG_DATUM_VON', 'VG_ORT', 'VG_RAUM',\n",
       "       'NUTZFALL', 'NUTZFALL_RAUM', 'MUSIKLEITER_NAME', 'KAPELLE_NAME',\n",
       "       'TARIF_NR', 'TARIF_BEZ', 'NUTZFALL_NR', 'VG_INKASSO', 'INKASSO_NETTO',\n",
       "       'INKASSO_BRUTTO', 'VERANST_GESCHAEFTSZEICHEN', 'VERANST_NAME',\n",
       "       'VERANST_STRASSE', 'VERANST_PLZ', 'VERANST_ORT',\n",
       "       'NUTZLIZNEHM_GESCHAEFTSZEICHEN', 'NUTZLIZNEHM_NAME',\n",
       "       'NUTZLIZNEHM_VORNAME', 'NUTZLIZNEHM_STRASSE', 'NUTZLIZNEHM_PLZ',\n",
       "       'NUTZLIZNEHM_ORT', 'LOCATION', 'BAND', 'PROMOTER'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IMP_ID                                 0\n",
       "GJ                                     0\n",
       "IMPORT                                 0\n",
       "MUFO_REFERENZ_N                  3205313\n",
       "BARCODE_NR                             0\n",
       "VERANST_SEGMENT                        0\n",
       "REKLA_JN                               0\n",
       "VG_DATUM_VON                           0\n",
       "VG_ORT                               222\n",
       "VG_RAUM                              155\n",
       "NUTZFALL                               0\n",
       "NUTZFALL_RAUM                        151\n",
       "MUSIKLEITER_NAME                 2104917\n",
       "KAPELLE_NAME                     1477728\n",
       "TARIF_NR                               0\n",
       "TARIF_BEZ                              0\n",
       "NUTZFALL_NR                            0\n",
       "VG_INKASSO                             0\n",
       "INKASSO_NETTO                    2933130\n",
       "INKASSO_BRUTTO                   2933130\n",
       "VERANST_GESCHAEFTSZEICHEN              0\n",
       "VERANST_NAME                         121\n",
       "VERANST_STRASSE                    20393\n",
       "VERANST_PLZ                         1225\n",
       "VERANST_ORT                          697\n",
       "NUTZLIZNEHM_GESCHAEFTSZEICHEN          0\n",
       "NUTZLIZNEHM_NAME                 1038426\n",
       "NUTZLIZNEHM_VORNAME              2941456\n",
       "NUTZLIZNEHM_STRASSE              1052479\n",
       "NUTZLIZNEHM_PLZ                  1038887\n",
       "NUTZLIZNEHM_ORT                  1038426\n",
       "LOCATION                             151\n",
       "BAND                             1453088\n",
       "PROMOTER                             121\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(allclaims_df.columns)\n",
    "# Count NaN values for each column in the dataframe\n",
    "display(allclaims_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMP_ID                                 \n",
    "GJ                               GeschÃ¤ftsJahr      \n",
    "IMPORT                           Distribution where the data came from      \n",
    "MUFO_REFERENZ_N                  \n",
    "BARCODE_NR                             \n",
    "VERANST_SEGMENT                  Event segment\n",
    "REKLA_JN                         Reclamation \n",
    "\n",
    "VG_DATUM_VON                     Event Date\n",
    "VG_ORT                           Event place\n",
    "VG_RAUM                          Event room\n",
    "\n",
    "NUTZFALL                         Usage of event or \n",
    "NUTZFALL_RAUM                    Use case Room or Music hall where the music is used\n",
    "\n",
    "MUSIKLEITER_NAME                 Music Leader name\n",
    "KAPELLE_NAME                     Chapel name\n",
    "\n",
    "TARIF_NR                         Tariff Number\n",
    "TARIF_BEZ                        Tariff Bez\n",
    "NUTZFALL_NR                      Usecase Number\n",
    "\n",
    "VG_INKASSO                       Event collection\n",
    "INKASSO_NETTO                    Net-Collection\n",
    "INKASSO_BRUTTO                   Gross-Collection\n",
    "VERANST_GESCHAEFTSZEICHEN        Event business sign or mark \n",
    "VERANST_NAME                     Event name\n",
    "VERANST_STRASSE                  Event street\n",
    "VERANST_PLZ                      Event post code\n",
    "VERANST_ORT                      Event place\n",
    "\n",
    "# Nutzungs Lizenznehmer - someone who has got the license(Usage licence) for the music works\n",
    "NUTZLIZNEHM_GESCHAEFTSZEICHEN    \n",
    "NUTZLIZNEHM_NAME                 name of person who aquired usage license\n",
    "NUTZLIZNEHM_VORNAME              surname of person who aquired usage license\n",
    "NUTZLIZNEHM_STRASSE              street of person who aquired usage license\n",
    "NUTZLIZNEHM_PLZ                  postcode of person who aquired usage license\n",
    "NUTZLIZNEHM_ORT                  place of person who aquired usage license\n",
    "\n",
    "LOCATION                         location - VG_ORT + VG_RAUM\n",
    "BAND                             band - KAPELLE_NAME and empty rows of kapelle name is filled with MUSIKLEITER_NAME\n",
    "PROMOTER                         promoter - VERANST_NAME + VERANST_PLZ\n",
    "\n",
    "VG_RAUM = 'IM FREIEN'(In Outside) or Name of the City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allclaims_df['VG_INKASSO'].max())\n",
    "print(allclaims_df['VG_INKASSO'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate Plotting - Distribution of the event collection in Euros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde - Kernel Density\n",
    "sns.displot(allclaims_df['VG_INKASSO'], kde=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VG_ORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the values seperated by comma\n",
    "contains_comma = allclaims_df[allclaims_df['VG_ORT'].str.contains(',') == True]\n",
    "non_comma_df = allclaims_df[allclaims_df['VG_ORT'].str.contains(',') == False]\n",
    "print(len(contains_comma))\n",
    "print(len(contains_comma['VG_ORT'].unique()))\n",
    "print(contains_comma['VG_ORT'])\n",
    "splitted_with_comma = contains_comma['VG_ORT'].str.split(r\",\", expand=True)\n",
    "print(len(splitted_with_comma[0].unique()))\n",
    "print(splitted_with_comma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------Non-commma-values--------\")\n",
    "print('No. of non-comma values : {}'.format(len(non_comma_df)))\n",
    "print('Non-comma unique values : {}'.format(len(non_comma_df['VG_ORT'].unique())))\n",
    "non_splitted_places = non_comma_df['VG_ORT']\n",
    "place_df = pd.concat([non_splitted_places,splitted_with_comma[0]])\n",
    "print('The number of unique places: {}'.format(len(place_df.unique())))\n",
    "# display('NaN values in df_raw : {}, NaN values in df: {}'.format(df_raw['VG_INKASSO'].isna().sum(), df['VG_INKASSO'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google maps API\n",
    "# how big the city is?\n",
    "# how close the location to the city centre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VG_RAUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sgopalakrish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the categories of VG_RAUM\n",
    "allclaims_df['VG_RAUM_clean']=allclaims_df['VG_RAUM'].astype(str).fillna('').map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "allclaims_df['VG_RAUM_tokenized']=allclaims_df['VG_RAUM_clean'].apply(word_tokenize, language='german')\n",
    "\n",
    "flat_list = [item for sublist in allclaims_df['VG_RAUM_tokenized'].tolist() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words = stopwords.words('german')\n",
    "english_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_german_stop_words = []\n",
    "def remove_special_chars_from_german_stopwords():\n",
    "    for each in german_stop_words:\n",
    "        each = each.replace('ÃŸ','SS')\n",
    "        each = each.upper()\n",
    "        each = each.replace('Ã„', 'AE')\n",
    "        each = each.replace('Ã–', 'OE')\n",
    "        each = each.replace('Ãœ', 'UE')\n",
    "        \n",
    "        cleaned_german_stop_words.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_special_chars_from_german_stopwords()\n",
    "text_wo_stop_words = [word for word in flat_list if word.lower() not in cleaned_german_stop_words]\n",
    "\n",
    "additional_stopwords = [\n",
    "    'ST', 'FREIEN', 'BAD', 'HAUS', 'EV', 'BERLIN', 'KATH', 'S', 'HOF', 'ALTE', 'MITTE', 'LUTH', 'MUENCHEN',\n",
    "    'IRISH', 'MUSIK', 'KULTUR', 'FUER', 'EVANG', 'MARITIM', 'KOELN', 'U', 'TURN', 'E', 'STUTTGART', 'ALTES',\n",
    "    'A', 'GASTES', 'THE', 'EUROPA', 'HANNOVER', 'STADT', 'BADEN', 'NUERNBERG', 'HAMBURG', 'NEUE',\n",
    "    'EVANGELISCHE', 'LEIPZIG', 'B', 'DRESDEN', 'BREMEN', 'PETER', '1','ALTER', 'AM', 'DIE', 'DER',\n",
    "    'DAS', 'DES', 'DEN', 'DEM', 'EIN', 'EINER', 'EINEM', 'EINES', 'EINE',\n",
    "    'MEIN', 'MEINER', 'MEINES', 'MEINEM', 'MEINE', 'UND'\n",
    "]\n",
    "\n",
    "text_wo_stop_words_2 = [word for word in text_wo_stop_words if word not in additional_stopwords]\n",
    "\n",
    "text_wo_stop_words_3 = ['KIRCHE' if 'KIRCHE' in word else word for word in text_wo_stop_words_2 ]\n",
    "\n",
    "# display(text_wo_stop_words_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_raum = FreqDist(text_wo_stop_words_3)\n",
    "print(fdist_raum)\n",
    "\n",
    "fdist_raum.plot(30,cumulative=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique band values: {}'.format(len(allclaims_df.BAND.unique())))\n",
    "# Null band values = 943181\n",
    "# Total Band values = 2029523\n",
    "print('Total non null band count: {}'.format(2029523-943181))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_german_stopwords = cleaned_german_stop_words + additional_stopwords + english_stop_words\n",
    "\n",
    "room_list_wo_stopwords = []\n",
    "for each_room in allclaims_df['VG_RAUM_clean'].tolist():\n",
    "    for each_stopword in all_german_stopwords:\n",
    "        # Remove stopword from each row in VG_RAUM_clean \n",
    "        each_room.replace(each_stopword,'')\n",
    "        \n",
    "    if 'KIRCHE' in each_room:\n",
    "        room_list_wo_stopwords.append('KIRCHE')\n",
    "    else:\n",
    "        room_list_wo_stopwords.append(each_room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_text_wo_stopwords = ','.join(room_list_wo_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allclaims_df['VG_RAUM_WO_STOPWORDS'] = room_list_wo_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get keywords Using Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "\n",
    "r.extract_keywords_from_text(joined_text_wo_stopwords)\n",
    "rankedList = r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordList           = []\n",
    "\n",
    "for keyword in rankedList:\n",
    "  keyword_updated       = keyword[1].split()\n",
    "  keyword_updated_string    = \" \".join(keyword_updated[:2])\n",
    "  keywordList.append(keyword_updated_string)\n",
    "#   if(len(keywordList)>9):\n",
    "#     break\n",
    "# print(keywordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_list = Counter(keywordList).most_common(30)\n",
    "\n",
    "keyword_list = []\n",
    "counts = []\n",
    "\n",
    "for each in most_common_list:\n",
    "    keyword_list.append(each[0])\n",
    "    counts.append(each[1])\n",
    "\n",
    "\n",
    "plt.plot(keyword_list, counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_vg_raum_rake = FreqDist(most_common_list)\n",
    "fdist_vg_raum_rake.plot(30,cumulative=False)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(73.15166945520723, 'view 200 dortmunder u 7 og leonie reygers terrasse 44137 dortmun'), \n",
    "(73.15166945520723, 'view 200 dortmunder u 7 og leonie reygers terrasse 44137 dortmun'), \n",
    "(73.15166945520723, 'view 200 dortmunder u 7 og leonie reygers terrasse 44137 dortmun'),\n",
    "(63.331820639281666, 'real pc 2319 1003 ks 49 1003 9000 saarbruecken'), \n",
    "(63.331820639281666, 'real pc 2319 1003 ks 49 1003 9000 saarbruecken'), \n",
    "(58.33024052020611, 'praeparandie sinzig praxis fuer psychiatrie neurologie und imp gespr'), \n",
    "(58.32403096060591, 'real pc 2319 1955 ks 49 1955 9000'), \n",
    "(58.32403096060591, 'real pc 2319 1955 ks 49 1955 9000'), \n",
    "(58.32403096060591, 'real pc 2319 1732 ks 49 1732 9000'), \n",
    "(58.32403096060591, 'real pc 2319 1732 ks 49 1732 9000'), \n",
    "(58.32403096060591, 'real pc 2319 1716 ks 49 1716 9000'), \n",
    "(58.32403096060591, 'real pc 2319 1716 ks 49 1716 9000'), \n",
    "(57.83704866897864, 'leistungsempfaenger hoeffner moebelges gmbh co kg pankstr 32 13357 b'),\n",
    "(56.887636709347206, 'moog 100 dortmunder u eg leonie reygers terrasse 44137 dortmund'), \n",
    "(56.527632852372335, 'hoeffner moebelges gmbh co kg rabenaustr 3 9 63584 gruendau'), \n",
    "(55.000939752317215, 'seelandhallen achtern diek gaestezentrum und spiel und spass scheun'), \n",
    "(54.97274199708599, 'bar ick koof mir dave lombardo wenn ick reich bin'), \n",
    "(53.74321256251726, 'leistungsempfaenger hoeffner moebelges gmbh co kg holsteiner ch 130'), \n",
    "(53.22730842308371, 'leistungsempfaenger hoeffner moebelges gmbh cokg inder schmalau40 9076'), \n",
    "(53.22730842308371, 'leistungsempfaenger hoeffner moebelges gmbh cokg inder schmalau40 9076'), \n",
    "(53.22730842308371, 'leistungsempfaenger hoeffner moebelges gmbh cokg inder schmalau40 9076'), \n",
    "(53.03487922918392, 'leistungsempfaenger hoeffner moebelges gmbh co kg hansestr 28 18182'), \n",
    "(53.01198737064888, 'europaeische stiftung der rahn dittrich group fuer bildung und kultur'), \n",
    "(53.01198737064888, 'europaeische stiftung der rahn dittrich group fuer bildung und kultur'), \n",
    "(50.92969436071396, 'zk u zentrum fuer kunst und urbanistik im ehem gueterbahnhof moabit'), \n",
    "(50.92969436071396, 'zk u zentrum fuer kunst und urbanistik im ehem gueterbahnhof moabit'), \n",
    "(50.92969436071396, 'zk u zentrum fuer kunst und urbanistik im ehem gueterbahnhof moabit'), \n",
    "(50.51442642054456, 'private kliniken dr dr med nebel vogtland klinik bad elster'), \n",
    "(50.51442642054456, 'private kliniken dr dr med nebel vogtland klinik bad elster'), \n",
    "(50.51442642054456, 'private kliniken dr dr med nebel vogtland klinik bad elster'),  \n",
    "(50.51442642054456, 'private kliniken dr dr med nebel vogtland klinik bad elster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming - removes suffixes and prefixes from word roots, \n",
    "# Lemmatization - maps the remaining root forms (which may not always be proper words) back to an actual word that occurs in natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get keywords using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    # pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "    # pos_tag = ['NOUN'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        # if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "        #     continue\n",
    "        # if(token.pos_ in pos_tag):\n",
    "        #     result.append(token.text)\n",
    "        print(token.text, token.pos_,token.dep_)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'NOUN', 'VERB']\n",
    "    # pos_tag = ['NOUN'] \n",
    "    # doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "        \n",
    "        # print(token.text, token.pos_,token.dep_)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(joined_text_wo_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raum_cleaned_df = (row.VG_RAUM_WO_STOPWORDS for row in allclaims_df.itertuples())\n",
    "output = []\n",
    "for doc in nlp.pipe(raum_cleaned_df):\n",
    "  output.append(get_keywords(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allclaims_df['VG_RAUM_KEYWORDS'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "9938851     [WERNER, VON, SIEMENS, SCHULZENTRUM]\n",
      "9938852                                 [KIRCHE]\n",
      "9938853           [KULTURHALLE, GRAFENRHEINFELD]\n",
      "9938854          [VEREINSHEIM, TSV, FRIESENRIED]\n",
      "9938855                      [PAUL, BAECK, HAUS]\n",
      "                            ...                 \n",
      "13949324         [AULA, HOCHSCHULE, FUER, MUSIK]\n",
      "13949326                  [JAZZCLUB, UNTERFAHRT]\n",
      "13949327                        [GOETHE, BUNKER]\n",
      "13949328                             [FEIERWERK]\n",
      "13949330                       [FRANKFURT, MAIN]\n",
      "Name: VG_RAUM_KEYWORDS, Length: 2029377, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(allclaims_df.VG_RAUM_KEYWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "9938851     WERNER,VON,SIEMENS,SCHULZENTRUM\n",
      "9938852                              KIRCHE\n",
      "9938853         KULTURHALLE,GRAFENRHEINFELD\n",
      "9938854         VEREINSHEIM,TSV,FRIESENRIED\n",
      "9938855                     PAUL,BAECK,HAUS\n",
      "                         ...               \n",
      "13949324         AULA,HOCHSCHULE,FUER,MUSIK\n",
      "13949326                JAZZCLUB,UNTERFAHRT\n",
      "13949327                      GOETHE,BUNKER\n",
      "13949328                          FEIERWERK\n",
      "13949330                     FRANKFURT,MAIN\n",
      "Name: VG_RAUM_KEYWORDS_STRINGS, Length: 2029377, dtype: object\n"
     ]
    }
   ],
   "source": [
    "allclaims_df['VG_RAUM_KEYWORDS_STRINGS'] = [','.join(map(str, l)) for l in allclaims_df['VG_RAUM_KEYWORDS']]\n",
    "print(allclaims_df['VG_RAUM_KEYWORDS_STRINGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "allclaims_df.VERANST_SEGMENT = allclaims_df['VERANST_SEGMENT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_output_list = [item for sublist in output for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_vg_raum_spacy = FreqDist(flat_output_list)\n",
    "fdist_vg_raum_spacy.plot(30,cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = Counter(flat_output_list).most_common(10000)\n",
    "for item in freq_words:\n",
    "  print(\"Word: {} and Count: {}\".format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic SVM Classifier model to classify event segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = allclaims_df[[\"VG_RAUM_KEYWORDS_STRINGS\",\"VG_DATUM_VON\",\"VG_ORT\",\"TARIF_BEZ\"]]\n",
    "y = allclaims_df['VERANST_SEGMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lowerclaim_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\00-Data-Exploration.ipynb Zelle 55\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000079?line=0'>1</a>\u001b[0m lowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_YEAR\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_VON\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000079?line=1'>2</a>\u001b[0m lowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_MONTH\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_VON\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mmonth\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000079?line=2'>3</a>\u001b[0m lowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_DAY_OF_WEEK\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mlowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_VON\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdayofweek\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lowerclaim_df' is not defined"
     ]
    }
   ],
   "source": [
    "allclaims_df['VG_DATUM_YEAR'] = allclaims_df['VG_DATUM_VON'].dt.year\n",
    "allclaims_df['VG_DATUM_MONTH'] = allclaims_df['VG_DATUM_VON'].dt.month\n",
    "allclaims_df['VG_DATUM_DAY_OF_WEEK']=allclaims_df['VG_DATUM_VON'].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lowerclaim_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\00-Data-Exploration.ipynb Zelle 56\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000080?line=0'>1</a>\u001b[0m seasons \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000080?line=1'>2</a>\u001b[0m lowerclaim_df[\u001b[39m'\u001b[39m\u001b[39mVG_DATUM_MONTH\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lowerclaim_df' is not defined"
     ]
    }
   ],
   "source": [
    "seasons = [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1]\n",
    "allclaims_df['VG_DATUM_MONTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "datetime64[ns]\n",
      "category\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "print(allclaims_df['VG_RAUM_KEYWORDS'].dtypes)\n",
    "print(allclaims_df['VG_DATUM_VON'].dtypes)\n",
    "print(allclaims_df['VG_ORT'].dtypes)\n",
    "print(allclaims_df['TARIF_BEZ'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgopalakrish\\AppData\\Local\\Temp\\ipykernel_26184\\2127196454.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['VG_DATUM_VON'] = pd.to_numeric(pd.to_datetime(X['VG_DATUM_VON']))\n"
     ]
    }
   ],
   "source": [
    "X['VG_DATUM_VON'] = pd.to_numeric(pd.to_datetime(X['VG_DATUM_VON']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'WERKSTATT,KULTUREN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\00-Data-Exploration.ipynb Zelle 58\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000087?line=0'>1</a>\u001b[0m svclassifier \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/00-Data-Exploration.ipynb#ch0000087?line=1'>2</a>\u001b[0m svclassifier\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[0;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    177\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    178\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    182\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'WERKSTATT,KULTUREN'"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the places by the state\n",
    "# Find the missing places using the PLZ or using the VG_Raum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are only 2 values in the INKASSO_NETTO and INKASSO_BRUTTO\n",
    "# There are no null values in VG_INKASSO\n",
    "# Lowest value of VG_INKASSO is 0.04 and highest value is 409.7\n",
    "# How could segment 2 (0 - 50 euros) and segment 3 (50-100 euros) would have high VG_INKASSO values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morethan100 = allclaims_df[allclaims_df['VG_INKASSO']>100]\n",
    "len(morethan100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values\n",
    "# VG_ORT - 146\n",
    "# VERANST_ORT  368\n",
    "# VG_RAUM/LOCATION - 95\n",
    "# VERANST_NAME/PROMOTER  103\n",
    "# TARIF_BEZ  0\n",
    "# BAND  943181\n",
    "# KAPELLE_NAME 960942\n",
    "# sns.barplot(x=allclaims_df['VG_ORT'], y=df['VERANST_SEGMENT'])\n",
    "# plt.show()\n",
    "\n",
    "#box plot Place/Customer Segment\n",
    "data = pd.concat([allclaims_df['VG_ORT'], df['VERANST_SEGMENT']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(80, 6))\n",
    "fig = sns.boxplot(x=\"VG_ORT\", y=\"VERANST_SEGMENT\", data=data)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x=allclaims_df['TARIF_BEZ'], y=df['VERANST_SEGMENT'])\n",
    "# plt.show()\n",
    "#box plot Tarif/Customer Segment\n",
    "data = pd.concat([allclaims_df['TARIF_BEZ'], df['VERANST_SEGMENT']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(80, 8))\n",
    "fig = sns.boxplot(x=\"TARIF_BEZ\", y=\"VERANST_SEGMENT\", data=data)\n",
    "# fig.axis(ymin=0, ymax=800000)\n",
    "plt.xticks(rotation=90)\n",
    "# 54 Tarifs used frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the relationship between tarif, customer segment and the band that performed\n",
    "sns.boxplot(x=\"TARIF_BEZ\", y=\"VERANST_SEGMENT\", hue=\"BAND\", data=allclaims_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the relationship between tarif, customer segment and the location the event was performed\n",
    "sns.boxplot(x=\"TARIF_BEZ\", y=\"VERANST_SEGMENT\", hue=\"LOCATION\", data=allclaims_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation of customer segments and other variables\n",
    "allclaims_df.corr()['VERANST_SEGMENT'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation of VG_INKASSO and other variables\n",
    "allclaims_df.corr()['VG_INKASSO'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allclaims_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(allclaims_df.corr(), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "125624270022b3522b0d9fce357b71cad5d467865128e7f38888e7b3f5116099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
