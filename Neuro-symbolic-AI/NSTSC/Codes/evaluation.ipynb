{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models_node import *\n",
    "from utils.datautils import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ---Intellizenz ---dataset\n",
      "\n",
      "\n",
      "X Train Data shape:\n",
      " (195254, 152)\n",
      "\n",
      "X Test Data shape:\n",
      " (151287, 152)\n",
      "\n",
      "Y Train Data shape:\n",
      " (195254,)\n",
      "\n",
      "Y Test Data shape:\n",
      " (151287,)\n",
      "The pronodenum:  0\n",
      "The maxnodenum:  0\n",
      "Model number :1 and Epochs :100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\Neuro-symbolic-AI\\NSTSC\\Codes\\utils\\train_utils.py:132: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  IR = sum(ytrain==1)/sum(ytrain==0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number :2 and Epochs :100\n",
      "Model number :3 and Epochs :100\n",
      "Model number :4 and Epochs :100\n",
      "Model number :5 and Epochs :100\n",
      "Model number :6 and Epochs :100\n",
      "The pronodenum:  1\n",
      "The maxnodenum:  1\n"
     ]
    }
   ],
   "source": [
    "Dataset_name = \"Intellizenz\"\n",
    "print('Start Training ---' + str(Dataset_name) + ' ---dataset\\n')\n",
    "dataset_path_ = 'C:/Saravana/Projects/Intellizenz/intellizenz-model-training/data'\n",
    "\n",
    "normalize_dataset = True\n",
    "Max_epoch = 100\n",
    "# model training\n",
    "Xtrain_raw, ytrain_raw, Xval_raw, yval_raw, Xtest_raw, ytest_raw \\\n",
    "    = Readdataset(dataset_path_, Dataset_name)\n",
    "Xtrain, Xval, Xtest = Multi_view(Xtrain_raw, Xval_raw, Xtest_raw)\n",
    "N, T = calculate_dataset_metrics(Xtrain)\n",
    "Tree = Train_model(Xtrain, Xval, ytrain_raw, yval_raw, epochs = Max_epoch,\\\n",
    "                    normalize_timeseries = normalize_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for dataset Intellizenz is --- 1.0\n"
     ]
    }
   ],
   "source": [
    "# model testing\n",
    "testaccu = Evaluate_model(Tree, Xtest, ytest_raw)\n",
    "print(\"Test accuracy for dataset {} is --- {}\".format(Dataset_name, testaccu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "125624270022b3522b0d9fce357b71cad5d467865128e7f38888e7b3f5116099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
