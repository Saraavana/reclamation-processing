{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Single-Label classification\n",
    "\n",
    "The natural extension of binary classification is a multi-class classification task.\n",
    "We first approach multi-class single-label classification, which makes the assumption that each example is assigned to one and only one label.\n",
    "\n",
    "We use the *Iris flower* data set, which consists of a classification into three mutually-exclusive classes; call these $A$, $B$ and $C$.\n",
    "\n",
    "While one could train three unary predicates $A(x)$, $B(x)$ and $C(x)$, it turns out to be more effective if this problem is modelled by a single binary predicate $P(x,l)$, where $l$ is a variable denoting a multi-class label, in this case classes $A$, $B$ or $C$.\n",
    "- This syntax allows one to write statements quantifying over the classes, e.g. $\\forall x ( \\exists l ( P(x,l)))$.\n",
    "- Since the classes are mutually-exclusive in this case, the output layer of the $\\mathtt{MLP}$ representing $P(x,l)$ will be a $\\mathtt{softmax}$ layer, instead of a $\\mathtt{sigmoid}$ function, to learn the probability of $A$, $B$ and $C$. This avoids writing additional constraints $\\lnot (A(x) \\land B(x))$, $\\lnot (A(x) \\land C(x))$, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit „Python 3.9.13 ('.venv': poetry)“ erfordert das ipykernel-Paket.\n",
      "\u001b[1;31mFühren Sie den folgenden Befehl aus, um „ipykernel“ in der Python-Umgebung zu installieren. \n",
      "\u001b[1;31mBefehl: „c:/Saravana/Projects/Intellizenz/intellizenz-model-training/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall“"
     ]
    }
   ],
   "source": [
    "import ltn\n",
    "import logging; logging.basicConfig(level=logging.INFO)\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Load the iris dataset: 50 samples from each of three species of iris flowers (setosa, virginica, versicolor), measured with four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "            'place_kirche', 'place_hotel', 'place_cafe',\n",
    "            'place_theater', 'place_club', 'place_halle',\n",
    "            'place_gaststaette', 'place_festhalle', 'place_kulturzentrum',\n",
    "            'place_festzelt', 'place_schloss', 'place_pub',\n",
    "            'place_stadthalle', 'place_park', 'place_gasthof',\n",
    "            'place_kabarett', 'place_arena', 'place_schlachthof',\n",
    "            'place_wandelhalle', 'place_turnhalle', 'place_buergerhaus',\n",
    "            'place_museum', 'place_rathaus', 'place_staatsbad',\n",
    "            'place_zelt', 'place_jazz', 'place_forum',\n",
    "            'place_gymnasium', 'place_schule', 'place_sporthalle', \n",
    "\n",
    "            'band_kurorchester bad wil', 'band_musikverein harmonie', 'band_kasalla',\n",
    "            'band_cat ballou', 'band_roncalli  royal orch', 'band_jugendblasorchester',\n",
    "            'band_kurorchester bad pyr', 'band_hoehner', 'band_paveier',\n",
    "            'band_domstuermer', 'band_kluengelkoepp', 'band_alleinunterhalter',\n",
    "            'band_the gregorian voices', 'band_brings', 'band_musica hungarica',\n",
    "            'band_concerto', 'band_bad salzuflen orches', 'band_musikverein stadtkap',\n",
    "            'band_salonorchester hunga', 'band_miljoe', 'band_raeuber',\n",
    "            'band_kabarett leipziger f', 'band_marita koellner', 'band_salon-orchester hung',\n",
    "            'band_blaeck foeoess', 'band_schuelerinnen und sc', 'band_romain vicente',\n",
    "            'band_staatliche kurkapell', 'band_musikzug der freiwil', 'band_funky marys',\n",
    "\n",
    "            'state_bavaria','state_rhineland-palatinate',\n",
    "            'state_baden-wuerttemberg',\t'state_north rhine-westphalia',\t\n",
    "            'state_thuringia','state_hesse',\t\n",
    "            'state_brandenburg', 'state_schleswig-holstein',\t\n",
    "            'state_berlin',\t'state_mecklenburg-western pomerania',\t\n",
    "            'state_lower saxony', 'state_hamburg',\t\n",
    "            'state_saarland', 'state_saxony-anhalt',\t\n",
    "            'state_saxony',\t'state_bremen',\n",
    "\n",
    "            'vg_datum_year','vg_datum_month','vg_datum_day_of_week','vg_datum_season', \n",
    "\n",
    "            'veranst_segment','vg_inkasso'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          place_kirche  place_hotel  place_cafe  place_theater  place_club  \\\n",
      "ID                                                                           \n",
      "12151712             0            0           0              0           0   \n",
      "12885094             0            0           0              0           0   \n",
      "10985840             0            0           0              0           0   \n",
      "10114364             0            1           0              0           0   \n",
      "13926216             0            0           0              0           0   \n",
      "\n",
      "          place_halle  place_gaststaette  place_festhalle  \\\n",
      "ID                                                          \n",
      "12151712            0                  0                0   \n",
      "12885094            0                  0                0   \n",
      "10985840            0                  0                0   \n",
      "10114364            0                  0                0   \n",
      "13926216            0                  0                0   \n",
      "\n",
      "          place_kulturzentrum  place_festzelt  ...  state_saarland  \\\n",
      "ID                                             ...                   \n",
      "12151712                    0               0  ...               0   \n",
      "12885094                    0               0  ...               0   \n",
      "10985840                    0               0  ...               0   \n",
      "10114364                    0               0  ...               0   \n",
      "13926216                    0               0  ...               0   \n",
      "\n",
      "          state_saxony-anhalt  state_saxony  state_bremen  vg_datum_year  \\\n",
      "ID                                                                         \n",
      "12151712                    0             0             0           2015   \n",
      "12885094                    0             0             0           2019   \n",
      "10985840                    0             0             0           2017   \n",
      "10114364                    0             0             0           2016   \n",
      "13926216                    0             0             0           2020   \n",
      "\n",
      "          vg_datum_month  vg_datum_day_of_week  vg_datum_season  \\\n",
      "ID                                                                \n",
      "12151712               8                     4                3   \n",
      "12885094               3                     5                2   \n",
      "10985840              10                     2                4   \n",
      "10114364               1                     6                1   \n",
      "13926216               8                     5                3   \n",
      "\n",
      "          veranst_segment  vg_inkasso  \n",
      "ID                                     \n",
      "12151712                4      191.52  \n",
      "12885094                3       57.84  \n",
      "10985840                2       15.94  \n",
      "10114364                4      807.98  \n",
      "13926216                2       19.76  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "# df_train = pd.read_csv(\"./iris_training.csv\")\n",
    "# df_test = pd.read_csv(\"./iris_test.csv\")\n",
    "\n",
    "df_train = pd.read_parquet(\"C:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\data\\export_training_features_2016_2020.parquet.gzip\")\n",
    "df_test = pd.read_parquet(\"C:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\data\\export_testing_features_2016_2020.parquet.gzip\")\n",
    "\n",
    "df_train = df_train[features]\n",
    "df_test = df_test[features]\n",
    "\n",
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = df_train.pop(\"veranst_segment\")\n",
    "labels_test = df_test.pop(\"veranst_segment\")\n",
    "batch_size = 64\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((df_train,labels_train)).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((df_test,labels_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTN\n",
    "\n",
    "Predicate with softmax `P(x,class)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"relu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(4)\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants to index/iterate on the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_A = ltn.Constant(0, trainable=False)\n",
    "class_B = ltn.Constant(1, trainable=False)\n",
    "class_C = ltn.Constant(2, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators and axioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features, labels, training=False):\n",
    "    x_A = ltn.Variable(\"x_A\",features[labels==0])\n",
    "    x_B = ltn.Variable(\"x_B\",features[labels==1])\n",
    "    x_C = ltn.Variable(\"x_C\",features[labels==2])\n",
    "    axioms = [\n",
    "        Forall(x_A,p([x_A,class_A],training=training)),\n",
    "        Forall(x_B,p([x_B,class_B],training=training)),\n",
    "        Forall(x_C,p([x_C,class_C],training=training))\n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all layers and the static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sat level nan\n"
     ]
    }
   ],
   "source": [
    "for features, labels in ds_test:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features,labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Define the metrics. While training, we measure:\n",
    "1. The level of satisfiability of the Knowledge Base of the training data.\n",
    "1. The level of satisfiability of the Knowledge Base of the test data.\n",
    "3. The training accuracy.\n",
    "4. The test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training and test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, labels):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, labels, training=True)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    sat = axioms(features, labels) # compute sat without dropout\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['train_accuracy'](tf.one_hot(labels,3),predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, labels):\n",
    "    # sat\n",
    "    sat = axioms(features, labels)\n",
    "    metrics_dict['test_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['test_accuracy'](tf.one_hot(labels,3),predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_sat_kb: nan, test_sat_kb: nan, train_accuracy: 0.5899, test_accuracy: 0.5896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\Neuro-symbolic-AI\\LTN\\logictensornetworks-master\\examples\\multiclass_classification\\multiclass-singlelabel.ipynb Zelle 21\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcommons\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m commons\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     EPOCHS,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     metrics_dict,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     ds_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     ds_test,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_step,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     test_step,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     csv_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mintellizenz_results.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     track_metrics\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Saravana/Projects/Intellizenz/intellizenz-model-training/Neuro-symbolic-AI/LTN/logictensornetworks-master/examples/multiclass_classification/multiclass-singlelabel.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\Neuro-symbolic-AI\\LTN\\logictensornetworks-master\\examples\\multiclass_classification\\commons.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, track_metrics, csv_path, scheduled_parameters)\u001b[0m\n\u001b[0;32m     40\u001b[0m     metrics\u001b[39m.\u001b[39mreset_states()\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m batch_elements \u001b[39min\u001b[39;00m ds_train:\n\u001b[1;32m---> 43\u001b[0m     train_step(\u001b[39m*\u001b[39mbatch_elements,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscheduled_parameters[epoch])\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m batch_elements \u001b[39min\u001b[39;00m ds_test:\n\u001b[0;32m     45\u001b[0m     test_step(\u001b[39m*\u001b[39mbatch_elements,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscheduled_parameters[epoch])\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Saravana\\Projects\\Intellizenz\\intellizenz-model-training\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import commons\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "commons.train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"intellizenz_results.csv\",\n",
    "    track_metrics=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "125624270022b3522b0d9fce357b71cad5d467865128e7f38888e7b3f5116099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
