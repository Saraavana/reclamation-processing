{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Single-Label classification\n",
    "\n",
    "The natural extension of binary classification is a multi-class classification task.\n",
    "We first approach multi-class single-label classification, which makes the assumption that each example is assigned to one and only one label.\n",
    "\n",
    "We use the Intelliznz data set, which consists of a classification into three mutually-exclusive classes; call these $A(0-50€)$, $B(50-100€)$ and $C(>100€)$.\n",
    "\n",
    "While one could train three unary predicates $A(x)$, $B(x)$ and $C(x)$, it turns out to be more effective if this problem is modelled by a single binary predicate $P(x,l)$, where $l$ is a variable denoting a multi-class label, in this case classes $A$, $B$ or $C$.\n",
    "- This syntax allows one to write statements quantifying over the classes, e.g. $\\forall x ( \\exists l ( P(x,l)))$.\n",
    "- Since the classes are mutually-exclusive in this case, the output layer of the $\\mathtt{MLP}$ representing $P(x,l)$ will be a $\\mathtt{softmax}$ layer, instead of a $\\mathtt{sigmoid}$ function, to learn the probability of $A$, $B$ and $C$. This avoids writing additional constraints $\\lnot (A(x) \\land B(x))$, $\\lnot (A(x) \\land C(x))$, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import logging; logging.basicConfig(level=logging.INFO)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Load the Intellizenz dataset: 1.7M samples from each of three classes of veranstaltung segments (0-50€, 50-100€, >100€)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "            'place_kirche', 'place_hotel', 'place_cafe',\n",
    "            'place_theater', 'place_club', 'place_halle',\n",
    "            'place_gaststaette', 'place_festhalle', 'place_kulturzentrum',\n",
    "            'place_festzelt', 'place_schloss', 'place_pub',\n",
    "            'place_stadthalle', 'place_park', 'place_gasthof',\n",
    "            'place_kabarett', 'place_arena', 'place_schlachthof',\n",
    "            'place_wandelhalle', 'place_turnhalle', 'place_buergerhaus',\n",
    "            'place_museum', 'place_rathaus', 'place_staatsbad',\n",
    "            'place_zelt', 'place_jazz', 'place_forum',\n",
    "            'place_gymnasium', 'place_schule', 'place_sporthalle', \n",
    "\n",
    "            'band_kurorchester bad wil', 'band_musikverein harmonie', 'band_kasalla',\n",
    "            'band_cat ballou', 'band_roncalli  royal orch', 'band_jugendblasorchester',\n",
    "            'band_kurorchester bad pyr', 'band_hoehner', 'band_paveier',\n",
    "            'band_domstuermer', 'band_kluengelkoepp', 'band_alleinunterhalter',\n",
    "            'band_the gregorian voices', 'band_brings', 'band_musica hungarica',\n",
    "            'band_concerto', 'band_bad salzuflen orches', 'band_musikverein stadtkap',\n",
    "            'band_salonorchester hunga', 'band_miljoe', 'band_raeuber',\n",
    "            'band_kabarett leipziger f', 'band_marita koellner', 'band_salon-orchester hung',\n",
    "            'band_blaeck foeoess', 'band_schuelerinnen und sc', 'band_romain vicente',\n",
    "            'band_staatliche kurkapell', 'band_musikzug der freiwil', 'band_funky marys',\n",
    "\n",
    "            'state_bavaria','state_rhineland-palatinate',\n",
    "            'state_baden-wuerttemberg',\t'state_north rhine-westphalia',\t\n",
    "            'state_thuringia','state_hesse',\t\n",
    "            'state_brandenburg', 'state_schleswig-holstein',\t\n",
    "            'state_berlin',\t'state_mecklenburg-western pomerania',\t\n",
    "            'state_lower saxony', 'state_hamburg',\t\n",
    "            'state_saarland', 'state_saxony-anhalt',\t\n",
    "            'state_saxony',\t'state_bremen',\n",
    "\n",
    "            'vg_datum_year','vg_datum_month','vg_datum_day_of_week','vg_datum_season', \n",
    "\n",
    "            'veranst_segment','vg_inkasso'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feautes used - 'VG_RAUM_KEYWORDS', 'VG_DATUM_VON', 'vg_state', 'BAND', 'PROMOTER'\n",
    "features_v3 = [\n",
    "'place_kirche', 'place_hotel', 'place_cafe',\n",
    " 'place_theater', 'place_club', 'place_halle',\n",
    " 'place_gaststaette', 'place_festhalle', 'place_kulturzentrum',\n",
    " 'place_festzelt', 'place_schloss', 'place_pub',\n",
    " 'place_stadthalle', 'place_park', 'place_gasthof',\n",
    " 'place_kabarett', 'place_arena', 'place_schlachthof',\n",
    " 'place_wandelhalle', 'place_turnhalle', 'place_buergerhaus',\n",
    " 'place_museum', 'place_rathaus', 'place_staatsbad',\n",
    " 'place_zelt', 'place_jazz', 'place_forum',\n",
    " 'place_gymnasium', 'place_schule', 'place_sporthalle',\n",
    "\n",
    "'band_kurorchester bad wil', 'band_musikverein harmonie', 'band_kasalla',\n",
    " 'band_cat ballou', 'band_roncalli  royal orch', 'band_jugendblasorchester',\n",
    " 'band_kurorchester bad pyr', 'band_hoehner', 'band_paveier',\n",
    " 'band_domstuermer', 'band_kluengelkoepp', 'band_alleinunterhalter',\n",
    " 'band_the gregorian voices', 'band_brings', 'band_musica hungarica',\n",
    " 'band_concerto', 'band_bad salzuflen orches', 'band_musikverein stadtkap',\n",
    " 'band_salonorchester hunga', 'band_miljoe', 'band_raeuber',\n",
    " 'band_kabarett leipziger f', 'band_marita koellner', 'band_salon-orchester hung',\n",
    " 'band_blaeck foeoess', 'band_schuelerinnen und sc', 'band_romain vicente',\n",
    " 'band_staatliche kurkapell', 'band_musikzug der freiwil', 'band_funky marys',\n",
    "\n",
    "\n",
    "'state_bavaria','state_rhineland-palatinate',\n",
    "'state_baden-wuerttemberg',\t'state_north rhine-westphalia',\t\n",
    "'state_thuringia','state_hesse',\t\n",
    "'state_brandenburg', 'state_schleswig-holstein',\t\n",
    "'state_berlin',\t'state_mecklenburg-western pomerania',\t\n",
    "'state_lower saxony', 'state_hamburg',\t\n",
    "'state_saarland', 'state_saxony-anhalt',\t\n",
    "'state_saxony',\t'state_bremen'\n",
    ",\n",
    "\n",
    "'vg_datum_year','vg_datum_month','vg_datum_day_of_week','vg_datum_season',\n",
    "\n",
    "'promoter_chorverband nrw e.v. e.v 44135', \n",
    "'promoter_live nation gmbh gmbh 60320', \n",
    "'promoter_schwaebischer chorverband e.v. e.v 70372',\n",
    "'promoter_trinity music gmbh 10823',\n",
    "'promoter_karsten jahnke konzertdirektion gmbh 20359',\n",
    "'promoter_fkp scorpio konzertproduktionen gmbh gmbh 22767',\n",
    "'promoter_prime entertainment gmbh 50672',\n",
    "'promoter_live nation gmbh 60320',\n",
    "'promoter_fraenkischer saengerbund e.v. e.v 96450',\n",
    "'promoter_semmel concerts entertainment gmbh 95445',\n",
    "'promoter_fkp scorpio konzertproduktionen gmbh 22767',\n",
    "'promoter_hessischer saengerbund e.v. e.v 61440',\n",
    "'promoter_trinity music gmbh gmbh 10823',\n",
    "'promoter_europa-park gmbh & co mack kg 77977',\n",
    "'promoter_badischer chorverband 1862 e.v. e.v 76133',\n",
    "'promoter_prime entertainment gmbh gmbh 50672',\n",
    "'promoter_irish pubs gaststaetten gmbh 14959',\n",
    "'promoter_gastro event gmbh 26802',\n",
    "'promoter_semmel concerts entertainment gmbh gmbh 95445',\n",
    "'promoter_backstage concerts gmbh 80639',\n",
    "'promoter_paul daly und paul fleming gbr 80331',\n",
    "'promoter_frankfurter kulturzentrum e.v 60388',\n",
    "'promoter_gisbert hiller 48317',\n",
    "'promoter_kulturzentrum schlachthof wiesbaden e.v. e.v 65189',\n",
    "'promoter_karsten jahnke konzertdirektion gmbh gmbh 20359',\n",
    "'promoter_bayerisches wirtshaus berlin gmbh gmbh 10178',\n",
    "'promoter_berninger musik & gastronomie gmbh 63739',\n",
    "'promoter_graeflicher park gmbh & co. kg gmbh & co. kg 33014',\n",
    "'promoter_thorsten wolf 04109',\n",
    "'promoter_circus roncalli gmbh 51063'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/sgopalakrish/Downloads/intellizenz-model-training/data/export_features_2016_2020_v3.parquet.gzip\")\n",
    "\n",
    "\n",
    "X = df[features_v3]\n",
    "y = df['veranst_segment'].astype('int')\n",
    "\n",
    "# Encode categorical labels\n",
    "l_enc = LabelEncoder()\n",
    "y = l_enc.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 ... 2 2 0]\n",
      "[2 0 2 ... 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train,y_train)).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((X_test,y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTN\n",
    "\n",
    "Predicate with softmax `P(x,class)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"relu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(110)#number of features\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants to index/iterate on the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_A = ltn.Constant(0, trainable=False)\n",
    "class_B = ltn.Constant(1, trainable=False)\n",
    "class_C = ltn.Constant(2, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators and axioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features, labels, training=False):\n",
    "    x_A = ltn.Variable(\"x_A\",features[labels==0])\n",
    "    x_B = ltn.Variable(\"x_B\",features[labels==1])\n",
    "    x_C = ltn.Variable(\"x_C\",features[labels==2])\n",
    "    axioms = [\n",
    "        Forall(x_A,p([x_A,class_A],training=training)),\n",
    "        Forall(x_B,p([x_B,class_B],training=training)),\n",
    "        Forall(x_C,p([x_C,class_C],training=training))\n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all layers and the static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sat level 0.00694\n"
     ]
    }
   ],
   "source": [
    "for features, labels in ds_test:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features,labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Define the metrics. While training, we measure:\n",
    "1. The level of satisfiability of the Knowledge Base of the training data.\n",
    "1. The level of satisfiability of the Knowledge Base of the test data.\n",
    "3. The training accuracy.\n",
    "4. The test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training and test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, labels):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, labels, training=True)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    sat = axioms(features, labels) # compute sat without dropout\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['train_accuracy'](tf.one_hot(labels,3),predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, labels):\n",
    "    # sat\n",
    "    sat = axioms(features, labels)\n",
    "    metrics_dict['test_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['test_accuracy'](tf.one_hot(labels,3),predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_sat_kb: 0.3203, test_sat_kb: 0.3543, train_accuracy: 0.3720, test_accuracy: 0.4192\n",
      "Epoch 20, train_sat_kb: 0.3708, test_sat_kb: 0.3710, train_accuracy: 0.4783, test_accuracy: 0.4703\n",
      "Epoch 40, train_sat_kb: 0.3717, test_sat_kb: 0.3719, train_accuracy: 0.4764, test_accuracy: 0.4816\n",
      "Epoch 60, train_sat_kb: 0.3720, test_sat_kb: 0.3718, train_accuracy: 0.4794, test_accuracy: 0.4793\n",
      "Epoch 80, train_sat_kb: 0.3721, test_sat_kb: 0.3723, train_accuracy: 0.4754, test_accuracy: 0.4739\n",
      "Epoch 100, train_sat_kb: 0.3722, test_sat_kb: 0.3722, train_accuracy: 0.4739, test_accuracy: 0.4853\n",
      "Epoch 120, train_sat_kb: 0.3723, test_sat_kb: 0.3721, train_accuracy: 0.4730, test_accuracy: 0.4702\n",
      "Epoch 140, train_sat_kb: 0.3725, test_sat_kb: 0.3724, train_accuracy: 0.4677, test_accuracy: 0.4612\n",
      "Epoch 160, train_sat_kb: 0.3724, test_sat_kb: 0.3725, train_accuracy: 0.4705, test_accuracy: 0.4735\n",
      "Epoch 180, train_sat_kb: 0.3725, test_sat_kb: 0.3725, train_accuracy: 0.4703, test_accuracy: 0.4690\n",
      "Epoch 200, train_sat_kb: 0.3725, test_sat_kb: 0.3724, train_accuracy: 0.4728, test_accuracy: 0.4792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [112], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommons\u001b[39;00m\n\u001b[0;32m      3\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcommons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintellizenz_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\Downloads\\intellizenz-model-training\\Neuro-symbolic-AI\\LTN\\commons.py:42\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, track_metrics, csv_path, scheduled_parameters)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m metrics \u001b[39min\u001b[39;00m metrics_dict\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m     40\u001b[0m     metrics\u001b[39m.\u001b[39mreset_states()\n\u001b[1;32m---> 42\u001b[0m \u001b[39mfor\u001b[39;00m batch_elements \u001b[39min\u001b[39;00m ds_train:\n\u001b[0;32m     43\u001b[0m     train_step(\u001b[39m*\u001b[39mbatch_elements,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscheduled_parameters[epoch])\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m batch_elements \u001b[39min\u001b[39;00m ds_test:\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3009\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3010\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3011\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3012\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[0;32m   3013\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[0;32m   3014\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import commons\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "commons.train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"intellizenz_results.csv\",\n",
    "    track_metrics=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('intellizenz-model-training-LRwJb8pv-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "17ce7e5e80fa8847c13f468233b8349b1468d0a77f7c99a15d53db37f56b8200"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
