{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Single-Label classification\n",
    "\n",
    "The natural extension of binary classification is a multi-class classification task.\n",
    "We first approach multi-class single-label classification, which makes the assumption that each example is assigned to one and only one label.\n",
    "\n",
    "We use the *Iris flower* data set, which consists of a classification into three mutually-exclusive classes; call these $A$, $B$ and $C$.\n",
    "\n",
    "While one could train three unary predicates $A(x)$, $B(x)$ and $C(x)$, it turns out to be more effective if this problem is modelled by a single binary predicate $P(x,l)$, where $l$ is a variable denoting a multi-class label, in this case classes $A$, $B$ or $C$.\n",
    "- This syntax allows one to write statements quantifying over the classes, e.g. $\\forall x ( \\exists l ( P(x,l)))$.\n",
    "- Since the classes are mutually-exclusive in this case, the output layer of the $\\mathtt{MLP}$ representing $P(x,l)$ will be a $\\mathtt{softmax}$ layer, instead of a $\\mathtt{sigmoid}$ function, to learn the probability of $A$, $B$ and $C$. This avoids writing additional constraints $\\lnot (A(x) \\land B(x))$, $\\lnot (A(x) \\land C(x))$, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import logging; logging.basicConfig(level=logging.INFO)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Load the Intellizenz dataset: 1.7M samples from each of three classes of veranstaltung segments (0-50€, 50-100€, >100€)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "            'place_kirche', 'place_hotel', 'place_cafe',\n",
    "            'place_theater', 'place_club', 'place_halle',\n",
    "            'place_gaststaette', 'place_festhalle', 'place_kulturzentrum',\n",
    "            'place_festzelt', 'place_schloss', 'place_pub',\n",
    "            'place_stadthalle', 'place_park', 'place_gasthof',\n",
    "            'place_kabarett', 'place_arena', 'place_schlachthof',\n",
    "            'place_wandelhalle', 'place_turnhalle', 'place_buergerhaus',\n",
    "            'place_museum', 'place_rathaus', 'place_staatsbad',\n",
    "            'place_zelt', 'place_jazz', 'place_forum',\n",
    "            'place_gymnasium', 'place_schule', 'place_sporthalle', \n",
    "\n",
    "            'band_kurorchester bad wil', 'band_musikverein harmonie', 'band_kasalla',\n",
    "            'band_cat ballou', 'band_roncalli  royal orch', 'band_jugendblasorchester',\n",
    "            'band_kurorchester bad pyr', 'band_hoehner', 'band_paveier',\n",
    "            'band_domstuermer', 'band_kluengelkoepp', 'band_alleinunterhalter',\n",
    "            'band_the gregorian voices', 'band_brings', 'band_musica hungarica',\n",
    "            'band_concerto', 'band_bad salzuflen orches', 'band_musikverein stadtkap',\n",
    "            'band_salonorchester hunga', 'band_miljoe', 'band_raeuber',\n",
    "            'band_kabarett leipziger f', 'band_marita koellner', 'band_salon-orchester hung',\n",
    "            'band_blaeck foeoess', 'band_schuelerinnen und sc', 'band_romain vicente',\n",
    "            'band_staatliche kurkapell', 'band_musikzug der freiwil', 'band_funky marys',\n",
    "\n",
    "            'state_bavaria','state_rhineland-palatinate',\n",
    "            'state_baden-wuerttemberg',\t'state_north rhine-westphalia',\t\n",
    "            'state_thuringia','state_hesse',\t\n",
    "            'state_brandenburg', 'state_schleswig-holstein',\t\n",
    "            'state_berlin',\t'state_mecklenburg-western pomerania',\t\n",
    "            'state_lower saxony', 'state_hamburg',\t\n",
    "            'state_saarland', 'state_saxony-anhalt',\t\n",
    "            'state_saxony',\t'state_bremen',\n",
    "\n",
    "            'vg_datum_year','vg_datum_month','vg_datum_day_of_week','vg_datum_season', \n",
    "\n",
    "            'veranst_segment','vg_inkasso'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feautes used - 'VG_RAUM_KEYWORDS', 'VG_DATUM_VON', 'vg_state', 'BAND', 'PROMOTER'\n",
    "features_v3 = ['place_kirche', 'place_hotel', 'place_cafe',\n",
    " 'place_theater', 'place_club', 'place_halle',\n",
    " 'place_gaststaette', 'place_festhalle', 'place_kulturzentrum',\n",
    " 'place_festzelt', 'place_schloss', 'place_pub',\n",
    " 'place_stadthalle', 'place_park', 'place_gasthof',\n",
    " 'place_kabarett', 'place_arena', 'place_schlachthof',\n",
    " 'place_wandelhalle', 'place_turnhalle', 'place_buergerhaus',\n",
    " 'place_museum', 'place_rathaus', 'place_staatsbad',\n",
    " 'place_zelt', 'place_jazz', 'place_forum',\n",
    " 'place_gymnasium', 'place_schule', 'place_sporthalle',\n",
    "\n",
    "'band_kurorchester bad wil', 'band_musikverein harmonie', 'band_kasalla',\n",
    " 'band_cat ballou', 'band_roncalli  royal orch', 'band_jugendblasorchester',\n",
    " 'band_kurorchester bad pyr', 'band_hoehner', 'band_paveier',\n",
    " 'band_domstuermer', 'band_kluengelkoepp', 'band_alleinunterhalter',\n",
    " 'band_the gregorian voices', 'band_brings', 'band_musica hungarica',\n",
    " 'band_concerto', 'band_bad salzuflen orches', 'band_musikverein stadtkap',\n",
    " 'band_salonorchester hunga', 'band_miljoe', 'band_raeuber',\n",
    " 'band_kabarett leipziger f', 'band_marita koellner', 'band_salon-orchester hung',\n",
    " 'band_blaeck foeoess', 'band_schuelerinnen und sc', 'band_romain vicente',\n",
    " 'band_staatliche kurkapell', 'band_musikzug der freiwil', 'band_funky marys',\n",
    "\n",
    "\n",
    "'state_bavaria','state_rhineland-palatinate',\n",
    "'state_baden-wuerttemberg',\t'state_north rhine-westphalia',\t\n",
    "'state_thuringia','state_hesse',\t\n",
    "'state_brandenburg', 'state_schleswig-holstein',\t\n",
    "'state_berlin',\t'state_mecklenburg-western pomerania',\t\n",
    "'state_lower saxony', 'state_hamburg',\t\n",
    "'state_saarland', 'state_saxony-anhalt',\t\n",
    "'state_saxony',\t'state_bremen',\n",
    "\n",
    "'vg_datum_year','vg_datum_month','vg_datum_day_of_week','vg_datum_season',\n",
    "\n",
    "'promoter_chorverband nrw e.v. e.v 44135', \n",
    "'promoter_live nation gmbh gmbh 60320', \n",
    "'promoter_schwaebischer chorverband e.v. e.v 70372',\n",
    "'promoter_trinity music gmbh 10823',\n",
    "'promoter_karsten jahnke konzertdirektion gmbh 20359',\n",
    "'promoter_fkp scorpio konzertproduktionen gmbh gmbh 22767',\n",
    "'promoter_prime entertainment gmbh 50672',\n",
    "'promoter_live nation gmbh 60320',\n",
    "'promoter_fraenkischer saengerbund e.v. e.v 96450',\n",
    "'promoter_semmel concerts entertainment gmbh 95445',\n",
    "'promoter_fkp scorpio konzertproduktionen gmbh 22767',\n",
    "'promoter_hessischer saengerbund e.v. e.v 61440',\n",
    "'promoter_trinity music gmbh gmbh 10823',\n",
    "'promoter_europa-park gmbh & co mack kg 77977',\n",
    "'promoter_badischer chorverband 1862 e.v. e.v 76133',\n",
    "'promoter_prime entertainment gmbh gmbh 50672',\n",
    "'promoter_irish pubs gaststaetten gmbh 14959',\n",
    "'promoter_gastro event gmbh 26802',\n",
    "'promoter_semmel concerts entertainment gmbh gmbh 95445',\n",
    "'promoter_backstage concerts gmbh 80639',\n",
    "'promoter_paul daly und paul fleming gbr 80331',\n",
    "'promoter_frankfurter kulturzentrum e.v 60388',\n",
    "'promoter_gisbert hiller 48317',\n",
    "'promoter_kulturzentrum schlachthof wiesbaden e.v. e.v 65189',\n",
    "'promoter_karsten jahnke konzertdirektion gmbh gmbh 20359',\n",
    "'promoter_bayerisches wirtshaus berlin gmbh gmbh 10178',\n",
    "'promoter_berninger musik & gastronomie gmbh 63739',\n",
    "'promoter_graeflicher park gmbh & co. kg gmbh & co. kg 33014',\n",
    "'promoter_thorsten wolf 04109',\n",
    "'promoter_circus roncalli gmbh 51063']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/sgopalakrish/Downloads/intellizenz-model-training/data/export_features_2016_2020_v3.parquet.gzip\")\n",
    "\n",
    "\n",
    "X = df[features_v3]\n",
    "y = df['veranst_segment'].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "print(y_train.dtypes)\n",
    "print(y_test.dtypes)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train,y_train)).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((X_test,y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTN\n",
    "\n",
    "Predicate with softmax `P(x,class)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"relu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(4)\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants to index/iterate on the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_A = ltn.Constant(0, trainable=False)\n",
    "class_B = ltn.Constant(1, trainable=False)\n",
    "class_C = ltn.Constant(2, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators and axioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features, labels, training=False):\n",
    "    x_A = ltn.Variable(\"x_A\",features[labels==0])\n",
    "    x_B = ltn.Variable(\"x_B\",features[labels==1])\n",
    "    x_C = ltn.Variable(\"x_C\",features[labels==2])\n",
    "    axioms = [\n",
    "        Forall(x_A,p([x_A,class_A],training=training)),\n",
    "        Forall(x_B,p([x_B,class_B],training=training)),\n",
    "        Forall(x_C,p([x_C,class_C],training=training))\n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all layers and the static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sat level nan\n"
     ]
    }
   ],
   "source": [
    "for features, labels in ds_test:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features,labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Define the metrics. While training, we measure:\n",
    "1. The level of satisfiability of the Knowledge Base of the training data.\n",
    "1. The level of satisfiability of the Knowledge Base of the test data.\n",
    "3. The training accuracy.\n",
    "4. The test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training and test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, labels):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, labels, training=True)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    sat = axioms(features, labels) # compute sat without dropout\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['train_accuracy'](tf.one_hot(labels,3),predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, labels):\n",
    "    # sat\n",
    "    sat = axioms(features, labels)\n",
    "    metrics_dict['test_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['test_accuracy'](tf.one_hot(labels,3),predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_sat_kb: nan, test_sat_kb: nan, train_accuracy: 0.5900, test_accuracy: 0.5902\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommons\u001b[39;00m\n\u001b[0;32m      3\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcommons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintellizenz_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\Downloads\\intellizenz-model-training\\Neuro-symbolic-AI\\LTN\\commons.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, track_metrics, csv_path, scheduled_parameters)\u001b[0m\n\u001b[0;32m     40\u001b[0m     metrics\u001b[39m.\u001b[39mreset_states()\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m batch_elements \u001b[39min\u001b[39;00m ds_train:\n\u001b[1;32m---> 43\u001b[0m     train_step(\u001b[39m*\u001b[39mbatch_elements,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscheduled_parameters[epoch])\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m batch_elements \u001b[39min\u001b[39;00m ds_test:\n\u001b[0;32m     45\u001b[0m     test_step(\u001b[39m*\u001b[39mbatch_elements,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscheduled_parameters[epoch])\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\sgopalakrish\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\intellizenz-model-training-LRwJb8pv-py3.9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import commons\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "commons.train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"intellizenz_results.csv\",\n",
    "    track_metrics=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('intellizenz-model-training-LRwJb8pv-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "17ce7e5e80fa8847c13f468233b8349b1468d0a77f7c99a15d53db37f56b8200"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
