{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Single-Label classification\n",
    "\n",
    "The natural extension of binary classification is a multi-class classification task.\n",
    "We first approach multi-class single-label classification, which makes the assumption that each example is assigned to one and only one label.\n",
    "\n",
    "We use the Intelliznz data set, which consists of a classification into three mutually-exclusive classes; call these $A(0-50€)$, $B(50-100€)$ and $C(>100€)$.\n",
    "\n",
    "While one could train three unary predicates $A(x)$, $B(x)$ and $C(x)$, it turns out to be more effective if this problem is modelled by a single binary predicate $P(x,l)$, where $l$ is a variable denoting a multi-class label, in this case classes $A$, $B$ or $C$.\n",
    "- This syntax allows one to write statements quantifying over the classes, e.g. $\\forall x ( \\exists l ( P(x,l)))$.\n",
    "- Since the classes are mutually-exclusive in this case, the output layer of the $\\mathtt{MLP}$ representing $P(x,l)$ will be a $\\mathtt{softmax}$ layer, instead of a $\\mathtt{sigmoid}$ function, to learn the probability of $A$, $B$ and $C$. This avoids writing additional constraints $\\lnot (A(x) \\land B(x))$, $\\lnot (A(x) \\land C(x))$, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import logging; logging.basicConfig(level=logging.INFO)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os, sys; \n",
    "column_path = os.path.dirname(os.path.realpath('C:/Users/sgopalakrish/Downloads/intellizenz-model-training/Neuro-symbolic-AI/column.py'))\n",
    "if sys.path.__contains__(column_path)==False:\n",
    "    sys.path.append(column_path)\n",
    "\n",
    "import column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Load the Intellizenz dataset: 1.7M samples from each of three classes of veranstaltung segments (0-50€, 50-100€, >100€)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = column.features_v7\n",
    "# features.append('tarif_bez')\n",
    "\n",
    "\n",
    "# features = column.features_v2 #140 features # doesn't include tarif_bez\n",
    "# data_path = column.data_path_2016_2020_v3\n",
    "# df = pd.read_parquet(data_path)\n",
    "\n",
    "\n",
    "features = column.features_v8 #78 features # Includes tarif_bez\n",
    "data_path = column.data_path_2016_2020_v4\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "class_frequency = df.groupby('veranst_segment')['veranst_segment'].transform('count')\n",
    "# df_sampled = df.sample(n=70000, weights=class_frequency, random_state=2)\n",
    "df_sampled = df.sample(n=300000, weights=class_frequency, random_state=2)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_sampled['tarif_bez'] = le.fit_transform(df_sampled['tarif_bez'])\n",
    "\n",
    "X = df_sampled[features]\n",
    "y = df_sampled['veranst_segment']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train,y_train)).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((X_test,y_test)).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTN\n",
    "\n",
    "Predicate with softmax `P(x,class)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"relu\") for s in hidden_layer_sizes] # hidden layer\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes) # fully connected layer #output layer\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(3)\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants to index/iterate on the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_A = ltn.Constant(0, trainable=False)\n",
    "class_B = ltn.Constant(1, trainable=False)\n",
    "class_C = ltn.Constant(2, trainable=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators and axioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features, labels, training=False):\n",
    "    x_A = ltn.Variable(\"x_A\",features[labels==0])\n",
    "    x_B = ltn.Variable(\"x_B\",features[labels==1])\n",
    "    x_C = ltn.Variable(\"x_C\",features[labels==2])\n",
    "    axioms = [\n",
    "        Forall(x_A,p([x_A,class_A],training=training)),\n",
    "        Forall(x_B,p([x_B,class_B],training=training)),\n",
    "        Forall(x_C,p([x_C,class_C],training=training))\n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all layers and the static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, labels in ds_test:\n",
    "    # print(len(features))\n",
    "    # print(len(labels==1))\n",
    "    print(labels==0)\n",
    "    # print(labels)\n",
    "\n",
    "    class_a_features = features[labels==0]\n",
    "    class_b_features = features[labels==0]\n",
    "    class_c_features = features[labels==0]\n",
    "    # class_a_features[inex][tarif_index]\n",
    "    \n",
    "    # print(fads[0][76])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, labels in ds_test:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features,labels))\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Define the metrics. While training, we measure:\n",
    "1. The level of satisfiability of the Knowledge Base of the training data.\n",
    "1. The level of satisfiability of the Knowledge Base of the test data.\n",
    "3. The training accuracy.\n",
    "4. The test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training and test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(features, labels):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, labels, training=True)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    sat = axioms(features, labels) # compute sat without dropout\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['train_accuracy'](tf.one_hot(labels,3),predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, labels):\n",
    "    # sat\n",
    "    sat = axioms(features, labels)\n",
    "    metrics_dict['test_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    metrics_dict['test_accuracy'](tf.one_hot(labels,3),predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commons\n",
    "\n",
    "# EPOCHS = 500\n",
    "EPOCHS = 200\n",
    "\n",
    "commons.train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    # csv_path=\"intellizenz_results_v1.csv\",\n",
    "    # csv_path=\"intellizenz_results_v3.csv\",\n",
    "    # csv_path=\"intellizenz_results_v4.csv\",\n",
    "    # csv_path=\"intellizenz_results_v5.csv\",\n",
    "    csv_path=\"intellizenz_results_v6.csv\",\n",
    "    track_metrics=20\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "# checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "\n",
    "# # Save the weights using the `checkpoint_path` format\n",
    "# logits_model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# # Save the weights\n",
    "# logits_model.save_weights('./checkpoints/d1.7m_loote_500ep.ckpt')\n",
    "\n",
    "# # Save the weights\n",
    "# logits_model.save_weights('./checkpoints/d300k_loote_200ep.ckpt') #78 features\n",
    "\n",
    "# Save the weights\n",
    "logits_model.save_weights('./checkpoints/d300k_140features_200ep.ckpt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new model instance\n",
    "# model = MLP(4)\n",
    "\n",
    "# # Restore the weights\n",
    "# model.load_weights('./checkpoints/d1.7m_loote_500ep.ckpt')\n",
    "\n",
    "# Create a new model instance\n",
    "model = MLP(3)\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/d300k_loote_200ep.ckpt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logits_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred_probas = []\n",
    "\n",
    "i = 0\n",
    "for batch_elements in ds_test:\n",
    "    features = batch_elements[0]\n",
    "    labels = batch_elements[1]\n",
    "    predictions = model(features)\n",
    "\n",
    "    labels_list = labels.numpy().tolist()\n",
    "    y_true.extend(labels_list)\n",
    "    \n",
    "    y_pred_prob = predictions[:,1].numpy().tolist()\n",
    "    y_pred_probas.append(y_pred_prob)\n",
    "\n",
    "    top = tf.argmax(tf.nn.softmax(predictions.numpy()), 1)\n",
    "\n",
    "    pred_list = top.numpy().tolist()\n",
    "    y_pred.extend(pred_list)\n",
    "\n",
    "print(len(y_pred))\n",
    "print(len(y_true))\n",
    "print(len(y_pred_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = [] # each value contains probability score for corresponding class\n",
    "for each in y_pred_probas:\n",
    "    for i in each:\n",
    "        probas.append(i)\n",
    "\n",
    "print(len(probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, labels=[0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the True labels and Prediction to One hot encoded representation such as: if true - 0, then [1 0 0], \n",
    "# if true - 1, then [0 1 0]\n",
    "y_true_binarize = label_binarize(y_true, classes=[*range(n_classes)])\n",
    "y_pred_binarize = label_binarize(y_pred, classes=[*range(n_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(n_classes):\n",
    "    label = ''\n",
    "    if i == 0:\n",
    "        label = 'Class 0(0-50€)'\n",
    "    elif i == 1:\n",
    "        label = 'Class 1(50-100€)'\n",
    "    else:\n",
    "        label = 'Class 2(>100€)'\n",
    "\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true_binarize[:, i],\n",
    "                                                        y_pred_binarize[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label=label)\n",
    "    \n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "# plt.title(\"Precision vs recall curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Satisfiability and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# file = pd.read_csv('intellizenz_results_v1.csv')\n",
    "# file = pd.read_csv('intellizenz_results_v2.csv')\n",
    "# file = pd.read_csv('intellizenz_results_v4.csv')\n",
    "# file = pd.read_csv('intellizenz_results_v5.csv')\n",
    "file = pd.read_csv('intellizenz_results_v6.csv')\n",
    "\n",
    "\n",
    "sat_train_acc = file['train_sat_kb']\n",
    "sat_test_acc = file['test_sat_kb']\n",
    "\n",
    "train_acc = file['train_accuracy']\n",
    "test_acc = file['test_accuracy']\n",
    "\n",
    "epochs = file['Epoch']\n",
    "\n",
    "plt.plot(epochs, sat_train_acc, 'g', label='train')\n",
    "plt.plot(epochs, sat_test_acc, 'b', label='test')\n",
    "# plt.title('Training and testing set satisfiability performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Satisfiability accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_acc, 'g', label='train')\n",
    "plt.plot(epochs, test_acc, 'b', label='test')\n",
    "# plt.title('Training and testing classification performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intellizenz-model-training-LRwJb8pv-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17ce7e5e80fa8847c13f468233b8349b1468d0a77f7c99a15d53db37f56b8200"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
