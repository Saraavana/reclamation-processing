{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e5b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:30:56.431624Z",
     "start_time": "2021-07-20T07:30:56.374774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2bf15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:31:09.032934Z",
     "start_time": "2021-07-20T07:30:58.681607Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logit, expit\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "import math\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30988fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:34:11.161597Z",
     "start_time": "2021-05-27T11:34:10.919451Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a34e23",
   "metadata": {},
   "source": [
    "# Import and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9c725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:46:32.214562Z",
     "start_time": "2021-07-20T07:43:38.829115Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/export_features_2016_2020.pkl.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a693a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:38:35.933740Z",
     "start_time": "2021-05-27T11:38:12.529231Z"
    }
   },
   "outputs": [],
   "source": [
    "df_orig = df.copy() # save all data for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235acb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:38:37.726651Z",
     "start_time": "2021-05-27T11:38:35.996573Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df_orig # get all data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73ef3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:46:32.320279Z",
     "start_time": "2021-07-20T07:46:32.216555Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features = ['location_count', 'location_mean', 'location_std',\n",
    " 'location_min', 'location_5%', 'location_10%', 'location_15%',\n",
    " 'location_20%', 'location_25%', 'location_30%', 'location_35%',\n",
    " 'location_40%', 'location_45%', 'location_50%', 'location_55%',\n",
    " 'location_60%', 'location_65%', 'location_70%', 'location_75%',\n",
    " 'location_80%', 'location_85%', 'location_90%', 'location_95%',\n",
    " 'location_max', \n",
    "                \n",
    " 'band_count', 'band_mean', 'band_std',\n",
    " 'band_min', 'band_5%', 'band_10%', 'band_15%', 'band_20%',\n",
    " 'band_25%', 'band_30%', 'band_35%', 'band_40%', 'band_45%',\n",
    " 'band_50%', 'band_55%', 'band_60%', 'band_65%', 'band_70%',\n",
    " 'band_75%', 'band_80%', 'band_85%', 'band_90%', 'band_95%',\n",
    " 'band_max', \n",
    "                \n",
    " 'promoter_count', 'promoter_mean', 'promoter_std',\n",
    " 'promoter_min', 'promoter_5%', 'promoter_10%', 'promoter_15%',\n",
    " 'promoter_20%', 'promoter_25%', 'promoter_30%', 'promoter_35%',\n",
    " 'promoter_40%', 'promoter_45%', 'promoter_50%', 'promoter_55%',\n",
    " 'promoter_60%', 'promoter_65%', 'promoter_70%', 'promoter_75%',\n",
    " 'promoter_80%', 'promoter_85%', 'promoter_90%', 'promoter_95%',\n",
    " 'promoter_max', \n",
    " \n",
    " 'vg_datum_year', 'vg_datum_month', 'vg_datum_day_of_week',\n",
    "                \n",
    " 'location_kirche',  'location_hotel', 'location_theater', 'location_cafe',\n",
    " 'location_stadthalle', 'location_buergerhaus', 'location_club', 'location_gaststaette',\n",
    " 'location_halle', 'location_festhalle', 'location_kurhaus', 'location_schloss',\n",
    " 'location_restaurant', 'location_kulturzentrum', 'location_festzelt', 'location_musikschule',\n",
    " 'location_mehrzweckhalle', 'location_pub', 'location_bar', 'location_gasthaus', 'location_turnhalle',\n",
    " 'location_kulturhaus', 'location_gymnasium', 'location_rathaus', 'location_gasthof',\n",
    " 'location_park', 'location_kabarett', 'location_schuetzenhalle', 'location_gemeindehalle',\n",
    " 'location_gemeindehaus', \n",
    "                \n",
    " 'band_musikverein', 'band_band', 'band_mv', 'band_duo', 'band_trio', 'band_musikkapelle',\n",
    " 'band_chor', 'band_blaskapelle', 'band_orchester', 'band_stadtkapelle', 'band_gbr',\n",
    " 'band_jazz', 'band_kurorchester', 'band_amp', 'band_ensemble', 'band_blasorchester',\n",
    " 'band_partyband', 'band_friends', 'band_blues', 'band_original', 'band_live',\n",
    " 'band_swing', 'band_musikzug', 'band_solo', 'band_mgv', 'band_jugendkapelle',\n",
    " 'band_sound', 'band_harmonie', 'band_black', 'band_ev']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66557ac3",
   "metadata": {},
   "source": [
    "Add Target Variables for Classifiers\n",
    "\n",
    "Encode segments for Classifier 1:\n",
    "\n",
    "    Variable y_clf1\n",
    "    Positive class (seg 4+) y_clf1=1\n",
    "    Negative class (seg 2 or 3) y_clf1=0\n",
    "\n",
    "Encode segments for Classifier 2:\n",
    "\n",
    "    Variable y_clf2\n",
    "    Positive class (seg 3) y_clf2=1\n",
    "    Negative class (seg 2) y_clf2=0\n",
    "    Segments >3 are \"encoded\" as np.NaN. These NaN values will be dropped before training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca927ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:46:34.156370Z",
     "start_time": "2021-07-20T07:46:32.323271Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:,'y_clf1']=(df.amount_segment.astype(int) > 3).values.astype(int)\n",
    "df.loc[:,'y_clf2']=df.amount_segment.apply(lambda x: 1 if x==3 else (0 if x==2 else np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8a1fe",
   "metadata": {},
   "source": [
    "# Get sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33687ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T08:35:54.719120Z",
     "start_time": "2021-05-12T08:35:40.358297Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get a sample of the DataFrame \n",
    "splitSample = StratifiedShuffleSplit(n_splits=1, test_size=0.01, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in splitSample.split(df[all_features], df.amount_segment):\n",
    "    df_sample=df.iloc[test_idx]\n",
    "    \n",
    "    plt.figure()\n",
    "    df.amount_segment.astype(int).value_counts().sort_index().plot.bar(color='r')\n",
    "    df_sample.amount_segment.astype(int).value_counts().sort_index().plot.bar(color='g')\n",
    "\n",
    "    plt.title('Inkasso-Segment')\n",
    "    plt.legend(['Full DF', 'Sample DF'])\n",
    "    plt.show()\n",
    "\n",
    "df=df_sample.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e866b89",
   "metadata": {},
   "source": [
    "# Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7c079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:46:34.267075Z",
     "start_time": "2021-07-20T07:46:34.158364Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_groups = ['location', 'band', 'promoter']\n",
    "\n",
    "feature_group_combinations = []\n",
    "for i in range(1, len(feature_groups) + 1):\n",
    "    comb = itertools.combinations(feature_groups, i)\n",
    "    feature_group_combinations += list(comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfa251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:46:34.380803Z",
     "start_time": "2021-07-20T07:46:34.269070Z"
    }
   },
   "outputs": [],
   "source": [
    "features={}\n",
    "\n",
    "features['location'] = ['location_count', 'location_mean', 'location_std',\n",
    " 'location_min', 'location_5%', 'location_10%', 'location_15%',\n",
    " 'location_20%', 'location_25%', 'location_30%', 'location_35%',\n",
    " 'location_40%', 'location_45%', 'location_50%', 'location_55%',\n",
    " 'location_60%', 'location_65%', 'location_70%', 'location_75%',\n",
    " 'location_80%', 'location_85%', 'location_90%', 'location_95%',\n",
    " 'location_max', 'location_kirche',  'location_hotel', 'location_theater', 'location_cafe',\n",
    " 'location_stadthalle', 'location_buergerhaus', 'location_club', 'location_gaststaette',\n",
    " 'location_halle', 'location_festhalle', 'location_kurhaus', 'location_schloss',\n",
    " 'location_restaurant', 'location_kulturzentrum', 'location_festzelt', 'location_musikschule',\n",
    " 'location_mehrzweckhalle', 'location_pub', 'location_bar', 'location_gasthaus', 'location_turnhalle',\n",
    " 'location_kulturhaus', 'location_gymnasium', 'location_rathaus', 'location_gasthof',\n",
    " 'location_park', 'location_kabarett', 'location_schuetzenhalle', 'location_gemeindehalle',\n",
    " 'location_gemeindehaus']\n",
    "\n",
    "features['band'] = ['band_count', 'band_mean', 'band_std',\n",
    " 'band_min', 'band_5%', 'band_10%', 'band_15%', 'band_20%',\n",
    " 'band_25%', 'band_30%', 'band_35%', 'band_40%', 'band_45%',\n",
    " 'band_50%', 'band_55%', 'band_60%', 'band_65%', 'band_70%',\n",
    " 'band_75%', 'band_80%', 'band_85%', 'band_90%', 'band_95%',\n",
    " 'band_max','band_musikverein', 'band_band', 'band_mv', 'band_duo', 'band_trio', 'band_musikkapelle',\n",
    " 'band_chor', 'band_blaskapelle', 'band_orchester', 'band_stadtkapelle', 'band_gbr',\n",
    " 'band_jazz', 'band_kurorchester', 'band_amp', 'band_ensemble', 'band_blasorchester',\n",
    " 'band_partyband', 'band_friends', 'band_blues', 'band_original', 'band_live',\n",
    " 'band_swing', 'band_musikzug', 'band_solo', 'band_mgv', 'band_jugendkapelle',\n",
    " 'band_sound', 'band_harmonie', 'band_black', 'band_ev']\n",
    "\n",
    "features['promoter']=['promoter_count', 'promoter_mean', 'promoter_std',\n",
    " 'promoter_min', 'promoter_5%', 'promoter_10%', 'promoter_15%',\n",
    " 'promoter_20%', 'promoter_25%', 'promoter_30%', 'promoter_35%',\n",
    " 'promoter_40%', 'promoter_45%', 'promoter_50%', 'promoter_55%',\n",
    " 'promoter_60%', 'promoter_65%', 'promoter_70%', 'promoter_75%',\n",
    " 'promoter_80%', 'promoter_85%', 'promoter_90%', 'promoter_95%',\n",
    " 'promoter_max']\n",
    "    \n",
    "features['date']=['vg_datum_year', 'vg_datum_month', 'vg_datum_day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b0680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:55:30.099248Z",
     "start_time": "2021-05-27T11:55:29.943328Z"
    }
   },
   "outputs": [],
   "source": [
    "model_features={}\n",
    "for feature_group_combination in feature_group_combinations:\n",
    "    model_name=\"_\".join(feature_group_combination)\n",
    "    model_features[model_name] = features['date']\n",
    "    for feature_group in feature_groups:\n",
    "        if feature_group in feature_group_combination:\n",
    "            model_features[model_name]=model_features[model_name]+features[feature_group]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c3f89",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb867286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T07:43:24.449555Z",
     "start_time": "2021-07-20T07:43:24.338853Z"
    }
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "def save_model(model_path, model, model_config):\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model.save_model(os.path.join(model_path, 'model')) # use xgboosts own save and load function to ensure compatibility\n",
    "    with open(os.path.join(model_path, 'model_config.json'), 'w') as fp:\n",
    "        json.dump(model_config, fp)\n",
    "    print(f\"saved model {model_path}\")\n",
    "\n",
    "#load saved model\n",
    "def load_model(model_path, model_type):\n",
    "    if model_type == 'classifier' :\n",
    "        model = xgb.XGBClassifier()\n",
    "    elif model_type == 'regression' :\n",
    "        model = xgb.XGBRegressor()\n",
    "    model.load_model(os.path.join(model_path, 'model'))\n",
    "    with open(os.path.join(model_path, 'model_config.json'), 'r') as fp:\n",
    "        model_config = json.load(fp)\n",
    "    return model, model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542b530",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db53e2",
   "metadata": {},
   "source": [
    "Define models for each feature group combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd416f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T08:06:24.835706Z",
     "start_time": "2021-05-12T08:06:24.735431Z"
    }
   },
   "outputs": [],
   "source": [
    "clf1_models = {}\n",
    "clf2_models = {}\n",
    "reg2_models = {}\n",
    "reg3_models = {}\n",
    "reg2_logit_models = {}\n",
    "reg3_logit_models = {}\n",
    "\n",
    "for feature_group_combination in feature_group_combinations:\n",
    "\n",
    "    model_name=\"_\".join(feature_group_combination)\n",
    "    \n",
    "    clf1_models[model_name]=xgb.XGBClassifier(n_estimators=1100, max_depth=9, use_label_encoder=False, objective='binary:logistic',eval_metric = 'error')\n",
    "    clf1_models[model_name].set_params(tree_method = 'gpu_hist')\n",
    "    clf2_models[model_name]=xgb.XGBClassifier(n_estimators=1100, max_depth=9, use_label_encoder=False, objective='binary:logistic',eval_metric = 'error')\n",
    "    clf2_models[model_name].set_params(tree_method = 'gpu_hist')\n",
    "    reg2_models[model_name]=xgb.XGBRegressor(n_estimators=700, max_depth=7, min_child_weight=5, objective='reg:squarederror')\n",
    "    reg2_models[model_name].set_params(tree_method = 'gpu_hist')\n",
    "    #reg2_logit_models[model_name]=xgb.XGBRegressor(n_estimators=700, max_depth=7, min_child_weight=5, objective='reg:squarederror')\n",
    "    #reg2_logit_models[model_name].set_params(tree_method = 'gpu_hist')\n",
    "    reg3_models[model_name]=xgb.XGBRegressor(n_estimators=700, max_depth=7, min_child_weight=5, objective='reg:squarederror')\n",
    "    reg3_models[model_name].set_params(tree_method = 'gpu_hist')\n",
    "    #reg3_logit_models[model_name]=xgb.XGBRegressor(n_estimators=700, max_depth=7, min_child_weight=5, objective='reg:squarederror')\n",
    "    #reg3_logit_models[model_name].set_params(tree_method = 'gpu_hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cc796",
   "metadata": {},
   "source": [
    "# Load Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb298fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_thresholds_clf1 = {}\n",
    "classifier_thresholds_clf2 = {}\n",
    "\n",
    "for feature_group_combination in feature_group_combinations:\n",
    "    model_name=\"_\".join(feature_group_combination)\n",
    "    print('Load Thresholds for {}'.format(model_name))\n",
    "\n",
    "    classifier_thresholds_clf1[model_name]=pd.read_pickle(('./thresholds/export_thresholds_{}_clf1.pkl.bz2').format(model_name))\n",
    "    classifier_thresholds_clf2[model_name]=pd.read_pickle(('./thresholds/export_thresholds_{}_clf2.pkl.bz2').format(model_name))\n",
    "\n",
    "    display(classifier_thresholds_clf1[model_name])\n",
    "    display(classifier_thresholds_clf2[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86064cee",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9cdc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T08:56:34.406642Z",
     "start_time": "2021-05-12T08:45:39.075050Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define FOR and FDR\n",
    "max_for_clf1 = 0.03\n",
    "max_for_clf2 = 0.05 #False omission rate\n",
    "max_fdr_clf2 = 0.05 #False discovery rate\n",
    "\n",
    "for feature_group_combination in feature_group_combinations:\n",
    "    model_name=\"_\".join(feature_group_combination)\n",
    "    print('Generating models for {}'.format(model_name))\n",
    "    \n",
    "    train_df=pd.DataFrame()\n",
    "    train_df=df[model_features[model_name]+['amount','amount_segment','y_clf1','y_clf2']].dropna(subset=model_features[model_name]).copy()\n",
    "        \n",
    "    # split in X and y for clf1\n",
    "    X_train_clf1 = train_df[model_features[model_name]]\n",
    "    y_train_clf1 = train_df.y_clf1\n",
    "    \n",
    "    # train clf1\n",
    "    clf1_models[model_name].fit(X_train_clf1, y_train_clf1)\n",
    "    print(\"CLF1 Train Score: {}\".format(clf1_models[model_name].score(X_train_clf1, y_train_clf1)))\n",
    "\n",
    "    # split in X and y for clf2\n",
    "    df_train_clf2 = train_df.dropna(subset=['y_clf2'])\n",
    "\n",
    "    X_train_clf2 = df_train_clf2[model_features[model_name]]\n",
    "    y_train_clf2 = df_train_clf2.y_clf2\n",
    "        \n",
    "    #train clf2\n",
    "    clf2_models[model_name].fit(X_train_clf2, y_train_clf2)\n",
    "    print(\"CLF2 Train Score: {}\".format(clf2_models[model_name].score(X_train_clf2, y_train_clf2)))\n",
    "\n",
    "    \n",
    "    \n",
    "    #split in X and y for reg2\n",
    "    df_train_reg2 = train_df[(train_df['amount_segment']==2) & \n",
    "                             (train_df['amount']>=0.00001) & \n",
    "                             (train_df['amount']<=49.9999)]\n",
    "    X_train_reg2 = df_train_reg2[model_features[model_name]]\n",
    "    y_train_reg2 = (df_train_reg2.amount/50).apply(logit)\n",
    "    \n",
    "    # train reg2\n",
    "    reg2_models[model_name].fit(X_train_reg2, y_train_reg2)\n",
    "    print(\"REG2 Train Score: {}\".format(reg2_models[model_name].score(X_train_reg2, y_train_reg2)))\n",
    "\n",
    "    \n",
    "    #split in X and y for reg3\n",
    "    df_train_reg3 = train_df[(train_df['amount_segment']==3) & \n",
    "                             (train_df['amount']>50) & \n",
    "                             (train_df['amount']<=99.9999)]\n",
    "\n",
    "    X_train_reg3 = df_train_reg3[model_features[model_name]]\n",
    "    y_train_reg3 = ((df_train_reg3.amount-50)/50).apply(logit)\n",
    "    \n",
    "    #train reg3\n",
    "    reg3_models[model_name].fit(X_train_reg3, y_train_reg3)\n",
    "    print(\"REG3 Train Score: {}\".format(reg3_models[model_name].score(X_train_reg3, y_train_reg3)))\n",
    "\n",
    "    \n",
    "    config={}\n",
    "    model_path={}\n",
    "    \n",
    "    #generate config\n",
    "    config['clf1']= {\n",
    "        \"model_type\": \"clf1\",\n",
    "        \"model_name\": model_name,\n",
    "        \"thresholds\": {\n",
    "            \"t_neg\": classifier_thresholds_clf1[model_name][classifier_thresholds_clf1[model_name]['max_for_clf1']==max_for_clf1]['t_neg_clf1'].values[0]\n",
    "        },\n",
    "        \"params\": clf1_models[model_name].get_xgb_params(),\n",
    "        \"features\": model_features[model_name]\n",
    "    }  \n",
    "    config['clf2']= {\n",
    "        \"model_type\": \"clf2\",\n",
    "        \"model_name\": model_name,\n",
    "        \"thresholds\": {\n",
    "            \"t_neg\": classifier_thresholds_clf2[model_name][classifier_thresholds_clf2[model_name]['max_for_clf2']==max_for_clf2]['t_neg_clf2'].values[0],\n",
    "            \"t_pos\": classifier_thresholds_clf2[model_name][classifier_thresholds_clf2[model_name]['max_fdr_clf2']==max_fdr_clf2]['t_pos_clf2'].values[0]\n",
    "\n",
    "        },\n",
    "        \"params\": clf2_models[model_name].get_xgb_params(),\n",
    "        \"features\": model_features[model_name]\n",
    "    }  \n",
    "    config['reg2']= {\n",
    "        \"model_type\": \"reg2\",\n",
    "        \"model_name\": model_name,\n",
    "        \"params\": reg2_models[model_name].get_xgb_params(),\n",
    "        \"features\": model_features[model_name]\n",
    "    }  \n",
    "    config['reg3']= {\n",
    "        \"model_type\": \"reg3\",\n",
    "        \"model_name\": model_name,\n",
    "        \"params\": reg3_models[model_name].get_xgb_params(),\n",
    "        \"features\": model_features[model_name]\n",
    "    }  \n",
    "    \n",
    "    #generate model paths\n",
    "    model_path['clf1'] = f'models/'+str(datetime.now().strftime('%Y-%m-%d'))+'/clf1/'+\"_\".join(sorted(feature_group_combination))\n",
    "    model_path['clf2'] = f'models/'+str(datetime.now().strftime('%Y-%m-%d'))+'/clf2/'+\"_\".join(sorted(feature_group_combination))\n",
    "    model_path['reg2'] = f'models/'+str(datetime.now().strftime('%Y-%m-%d'))+'/reg2/'+\"_\".join(sorted(feature_group_combination))\n",
    "    model_path['reg3'] = f'models/'+str(datetime.now().strftime('%Y-%m-%d'))+'/reg3/'+\"_\".join(sorted(feature_group_combination))\n",
    "    \n",
    "    #save models\n",
    "    save_model(model_path['clf1'], clf1_models[model_name], config['clf1'])\n",
    "    save_model(model_path['clf2'], clf2_models[model_name], config['clf2'])\n",
    "    save_model(model_path['reg2'], reg2_models[model_name], config['reg2'])\n",
    "    save_model(model_path['reg3'], reg3_models[model_name], config['reg3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacdb8c",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6d561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T08:04:39.044672Z",
     "start_time": "2021-07-20T07:50:59.796878Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_paths_clf=[\n",
    "    f'models/2021-07-17/clf1/location',\n",
    "    f'models/2021-07-17/clf2/location',\n",
    "    f'models/2021-07-17/clf1/band',\n",
    "    f'models/2021-07-17/clf2/band',\n",
    "    f'models/2021-07-17/clf1/promoter',\n",
    "    f'models/2021-07-17/clf2/promoter',\n",
    "    f'models/2021-07-17/clf1/band_location',\n",
    "    f'models/2021-07-17/clf2/band_location',\n",
    "    f'models/2021-07-17/clf1/location_promoter',\n",
    "    f'models/2021-07-17/clf2/location_promoter',\n",
    "    f'models/2021-07-17/clf1/band_promoter',\n",
    "    f'models/2021-07-17/clf2/band_promoter',\n",
    "    f'models/2021-07-17/clf1/band_location_promoter',\n",
    "    f'models/2021-07-17/clf2/band_location_promoter'\n",
    "]\n",
    "\n",
    "model_paths_reg=[\n",
    "    f'models/2021-07-17/reg2/location',\n",
    "    f'models/2021-07-17/reg3/location',\n",
    "    f'models/2021-07-17/reg2/band',\n",
    "    f'models/2021-07-17/reg3/band',\n",
    "    f'models/2021-07-17/reg2/promoter',\n",
    "    f'models/2021-07-17/reg3/promoter',\n",
    "    f'models/2021-07-17/reg2/band_location',\n",
    "    f'models/2021-07-17/reg3/band_location',\n",
    "    f'models/2021-07-17/reg2/location_promoter',\n",
    "    f'models/2021-07-17/reg3/location_promoter',\n",
    "    f'models/2021-07-17/reg2/band_promoter',\n",
    "    f'models/2021-07-17/reg3/band_promoter',\n",
    "    f'models/2021-07-17/reg2/band_location_promoter',\n",
    "    f'models/2021-07-17/reg3/band_location_promoter'\n",
    "]\n",
    "\n",
    "t_neg_clf1={}\n",
    "t_neg_clf2={}\n",
    "t_pos_clf2={}\n",
    "\n",
    "clf1_models={}\n",
    "clf2_models={}\n",
    "reg2_models={}\n",
    "reg3_models={}\n",
    "\n",
    "for model_path in model_paths_clf:\n",
    "    print(model_path)\n",
    "    clf, config = load_model(model_path, 'classifier')\n",
    "    model_name=config['model_name']\n",
    "\n",
    "    #print(config)\n",
    "      \n",
    "    if config['model_type']=='clf1':\n",
    "        test_df = df.dropna(subset=config['features']).copy() \n",
    "        X = test_df[config['features']]\n",
    "        y = test_df.y_clf1\n",
    "        t_neg_clf1[model_name]=config['thresholds']['t_neg']\n",
    "        clf1_models[model_name]=clf\n",
    "    elif config['model_type']=='clf2':\n",
    "        test_df = df.dropna(subset=config['features']+['y_clf2']).copy() \n",
    "        X = test_df[config['features']]\n",
    "        y = test_df.y_clf2\n",
    "        t_neg_clf2[model_name]=config['thresholds']['t_neg']\n",
    "        t_pos_clf2[model_name]=config['thresholds']['t_pos']\n",
    "        clf2_models[model_name]=clf\n",
    "\n",
    "    y_pred = clf.predict(X)\n",
    "    \n",
    "    print(\"{} model Train Accuracy Score = {}\".format(model_name, accuracy_score(y, y_pred)))\n",
    "        \n",
    "    pd.Series(clf.feature_importances_,\n",
    "          index=config['features']).plot.bar(figsize=(20, 4), color='#d00007')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "for model_path in model_paths_reg:\n",
    "    print(model_path)\n",
    "    reg, config = load_model(model_path, 'regression')\n",
    "    model_name=config['model_name']\n",
    "\n",
    "    #print(config)\n",
    "\n",
    "    if config['model_type']=='reg2':\n",
    "        test_df = df[(df['amount_segment']==2) & \n",
    "                    (df['amount']>0) & \n",
    "                    (df['amount']<=50)].dropna(subset=config['features']).copy()\n",
    "        X = test_df[config['features']]\n",
    "        y = test_df.amount\n",
    "        reg2_models[model_name]=reg\n",
    "    elif config['model_type']=='reg3':\n",
    "        test_df = df[(df['amount_segment']==3) & \n",
    "                    (df['amount']>50) & \n",
    "                    (df['amount']<=100)].dropna(subset=config['features']).copy()\n",
    "        X = test_df[config['features']]\n",
    "        y = test_df.amount\n",
    "        reg3_models[model_name]=reg\n",
    "\n",
    "    y_pred = reg.predict(X)\n",
    "    \n",
    "    if config['model_type']=='reg2':\n",
    "        y_pred = pd.Series(y_pred).apply(expit)*50\n",
    "    elif config['model_type']=='reg3':\n",
    "        y_pred = pd.Series(y_pred).apply(expit)*50+50\n",
    "\n",
    "    print(\"{} model Train R2 Score = {}\".format(model_name, r2_score(y, y_pred)))\n",
    "    print(\"{} model Train MSE Score = {}\".format(model_name, mean_squared_error(y, y_pred)))\n",
    "        \n",
    "    pd.Series(reg.feature_importances_,\n",
    "          index=config['features']).plot.bar(figsize=(20, 4), color='#d00007')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399b209",
   "metadata": {},
   "source": [
    "# The function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bda06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:54:59.599962Z",
     "start_time": "2021-05-27T11:54:58.871893Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_predict(df_features, clf1, clf2, reg1, reg2, t_neg1, t_neg2, t_pos2):\n",
    "    prediction_result=pd.DataFrame(columns=['y_pred_proba_clf1',\n",
    "                                           'y_pred_proba_clf2',\n",
    "                                           'y_pred_clf1',\n",
    "                                           'y_pred_clf2',\n",
    "                                            'y_pred_reg2',\n",
    "                                            'y_pred_reg3',\n",
    "                                           'segment',\n",
    "                                           'amount'])\n",
    "\n",
    "    y_pred_proba_clf1 = clf1.predict_proba(df_features)[:, 1]\n",
    "    y_pred_proba_clf2 = clf2.predict_proba(df_features)[:, 1]\n",
    "    y_pred_reg2_logit=reg2.predict(df_features)\n",
    "    y_pred_reg3_logit=reg3.predict(df_features)\n",
    "    \n",
    "    prediction_result.y_pred_proba_clf1=y_pred_proba_clf1\n",
    "    prediction_result.y_pred_proba_clf2=y_pred_proba_clf2\n",
    "    prediction_result.y_pred_reg2 = pd.Series(y_pred_reg2_logit).apply(expit)*50\n",
    "    prediction_result.y_pred_reg3 = pd.Series(y_pred_reg3_logit).apply(expit)*50+50\n",
    "    \n",
    "    prediction_result['y_pred_proba_clf1']=prediction_result['y_pred_proba_clf1'].apply(lambda x: format(float(x),\".8f\")).astype(float)\n",
    "    prediction_result['y_pred_proba_clf2']=prediction_result['y_pred_proba_clf2'].apply(lambda x: format(float(x),\".8f\")).astype(float)\n",
    "    \n",
    "    prediction_result['y_pred_clf1']=prediction_result['y_pred_proba_clf1'].apply(lambda x: '2 or 3' if x <= t_neg1 else '4+')\n",
    "    prediction_result['y_pred_clf2']=prediction_result['y_pred_proba_clf2'].apply(lambda x: '2' if x<=t_neg2 else \n",
    "                                                ('2?' if x<=0.5 else \n",
    "                                                 ('3?' if x<=t_pos2 else '3')))\n",
    "    \n",
    "    prediction_result['pred_segment']=prediction_result.apply(lambda x: x['y_pred_clf1'] if x['y_pred_clf1']=='4+' else x['y_pred_clf2'], axis=1)\n",
    "\n",
    "    prediction_result['pred_amount']=prediction_result.apply(lambda x: \n",
    "                                                        x['y_pred_reg2'] if '2' in x.pred_segment\n",
    "                                                        else (x['y_pred_reg3'] if '3' in x.pred_segment \n",
    "                                                        else np.nan), axis=1)\n",
    "    \n",
    "    prediction_result=prediction_result[['pred_segment','pred_amount']].copy()\n",
    "    \n",
    "    return prediction_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1659634",
   "metadata": {},
   "source": [
    "# Call the function for all feature combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e4dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:09:33.733869Z",
     "start_time": "2021-05-27T11:55:36.412297Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for feature_group_combination in feature_group_combinations:\n",
    "    model_name=\"_\".join(feature_group_combination)\n",
    "    print('Make prediction for {}'.format(model_name))\n",
    "    \n",
    "    model_features = features['date']\n",
    "    for feature_group in feature_groups:\n",
    "        if feature_group in feature_group_combination:\n",
    "            model_features=model_features+features[feature_group]\n",
    "    \n",
    "    df_test=df[model_features].dropna(subset=model_features).copy()\n",
    "    \n",
    "    clf1 = clf1_models[model_name]\n",
    "    clf2 = clf2_models[model_name]\n",
    "    reg2 = reg2_models[model_name]\n",
    "    reg3 = reg3_models[model_name]\n",
    "    \n",
    "    results[model_name]=make_predict(df_test,clf1, clf2, reg2, reg3, \n",
    "             t_neg_clf1[model_name],\n",
    "             t_neg_clf2[model_name],\n",
    "             t_pos_clf2[model_name])\n",
    "\n",
    "\n",
    "    test = pd.concat([df[['y_clf1','y_clf2','amount']].reset_index(),results[model_name]],axis=1)\n",
    "\n",
    "    \n",
    "    test_reg = test.dropna(subset=['pred_amount'])\n",
    "   \n",
    "    print(math.sqrt(mean_squared_error(test_reg.amount,test_reg.pred_amount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a2167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "125624270022b3522b0d9fce357b71cad5d467865128e7f38888e7b3f5116099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
